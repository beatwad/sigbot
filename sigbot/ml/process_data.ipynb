{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/home/alex/.local/lib/python3.10/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from os import environ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from indicators import indicators\n",
    "from datetime import timedelta\n",
    "from tqdm.auto import tqdm\n",
    "from config.config import ConfigFactory\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from shaphypetune import BoostBoruta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score, precision_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    collect_data = True # create new dataset or load previous\n",
    "    select_features = True\n",
    "    train_NN = False\n",
    "    train_LGBM = True\n",
    "    n_repeats = 1\n",
    "    n_folds = 5\n",
    "    cls_target_ratio = 1.021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and add indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e06e0666ac493690d1bde66e00ea5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc152781dd164c0cb58b1d5fd8d0392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stoch_slowk</th>\n",
       "      <th>stoch_slowd</th>\n",
       "      <th>stoch_slowk_dir</th>\n",
       "      <th>...</th>\n",
       "      <th>linear_reg_angle_prev_72</th>\n",
       "      <th>macd_prev_72</th>\n",
       "      <th>macdsignal_prev_72</th>\n",
       "      <th>macdhist_prev_72</th>\n",
       "      <th>macd_dir_prev_72</th>\n",
       "      <th>macdsignal_dir_prev_72</th>\n",
       "      <th>atr_prev_72</th>\n",
       "      <th>close_smooth_prev_72</th>\n",
       "      <th>target</th>\n",
       "      <th>ttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-10 21:00:00</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>227818.00</td>\n",
       "      <td>58.380200</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>34.523810</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.856226</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.318808</td>\n",
       "      <td>0.227337</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-15 15:00:00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>250135.00</td>\n",
       "      <td>58.463239</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>53.174603</td>\n",
       "      <td>0.357436</td>\n",
       "      <td>...</td>\n",
       "      <td>5.250146</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.229362</td>\n",
       "      <td>0.110533</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-21 19:00:00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>49801.00</td>\n",
       "      <td>45.480088</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>61.904762</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.078633</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-1.898082</td>\n",
       "      <td>-0.192558</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-25 15:00:00</td>\n",
       "      <td>0.3970</td>\n",
       "      <td>0.3980</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>304916.80</td>\n",
       "      <td>36.897427</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>43.650794</td>\n",
       "      <td>-0.069109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303562</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>-0.292488</td>\n",
       "      <td>-0.109834</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0.398667</td>\n",
       "      <td>0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-25 15:00:00</td>\n",
       "      <td>6.8900</td>\n",
       "      <td>6.9100</td>\n",
       "      <td>6.8900</td>\n",
       "      <td>6.9000</td>\n",
       "      <td>3986.13</td>\n",
       "      <td>30.533005</td>\n",
       "      <td>14.404762</td>\n",
       "      <td>18.392857</td>\n",
       "      <td>-0.204445</td>\n",
       "      <td>...</td>\n",
       "      <td>11.812509</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>-0.003283</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>-0.946146</td>\n",
       "      <td>-0.453481</td>\n",
       "      <td>0.088674</td>\n",
       "      <td>6.850417</td>\n",
       "      <td>0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    open    high     low   close     volume        rsi  \\\n",
       "0 2022-09-10 21:00:00  0.9999  0.9999  0.9998  0.9998  227818.00  58.380200   \n",
       "1 2022-09-15 15:00:00  1.0000  1.0000  0.9999  1.0000  250135.00  58.463239   \n",
       "2 2022-09-21 19:00:00  1.0000  1.0000  0.9999  0.9999   49801.00  45.480088   \n",
       "3 2022-12-25 15:00:00  0.3970  0.3980  0.3930  0.3960  304916.80  36.897427   \n",
       "4 2022-12-25 15:00:00  6.8900  6.9100  6.8900  6.9000    3986.13  30.533005   \n",
       "\n",
       "   stoch_slowk  stoch_slowd  stoch_slowk_dir  ...  linear_reg_angle_prev_72  \\\n",
       "0    35.714286    34.523810         0.205808  ...                 -0.856226   \n",
       "1    64.285714    53.174603         0.357436  ...                  5.250146   \n",
       "2    57.142857    61.904762        -0.066667  ...                  5.078633   \n",
       "3    42.857143    43.650794        -0.069109  ...                  0.303562   \n",
       "4    14.404762    18.392857        -0.204445  ...                 11.812509   \n",
       "\n",
       "   macd_prev_72  macdsignal_prev_72  macdhist_prev_72  macd_dir_prev_72  \\\n",
       "0     -0.000020           -0.000010         -0.000009          0.318808   \n",
       "1      0.000016            0.000011          0.000006          0.229362   \n",
       "2      0.000006           -0.000004          0.000010         -1.898082   \n",
       "3     -0.000151           -0.000647          0.000496         -0.292488   \n",
       "4      0.028818           -0.003283          0.032101         -0.946146   \n",
       "\n",
       "   macdsignal_dir_prev_72  atr_prev_72  close_smooth_prev_72  target  ttype  \n",
       "0                0.227337     0.000114              1.000004       0    buy  \n",
       "1                0.110533     0.000113              0.999742       0    buy  \n",
       "2               -0.192558     0.000113              0.999988       0    buy  \n",
       "3               -0.109834     0.003108              0.398667       0   sell  \n",
       "4               -0.453481     0.088674              6.850417       0   sell  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11601, 385)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set environment variable\n",
    "environ[\"ENV\"] = \"1h_4h\"\n",
    "\n",
    "# Get configs\n",
    "configs = ConfigFactory.factory(environ).configs\n",
    "\n",
    "def get_file(ticker):\n",
    "    ''' Find files buy ticker names, file names can be in different formats '''\n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def add_indicators(df, ttype, configs):\n",
    "    # add RSI\n",
    "    rsi = indicators.RSI(ttype, configs)\n",
    "    df = rsi.get_indicator(df, '', '', 0)\n",
    "    # add RSI\n",
    "    stoch = indicators.STOCH(ttype, configs)\n",
    "    df = stoch.get_indicator(df, '', '', 0)\n",
    "    # add Trend\n",
    "    trend = indicators.Trend(ttype, configs)\n",
    "    df = trend.get_indicator(df, '', '', 0)\n",
    "    # add MACD\n",
    "    macd = indicators.MACD(ttype, configs)\n",
    "    df = macd.get_indicator(df, '', '', 0)\n",
    "    # add ATR\n",
    "    atr = indicators.ATR(ttype, configs)\n",
    "    df = atr.get_indicator(df, '', '', 0)\n",
    "    # add SMA\n",
    "    # sma = indicators.SMA(ttype, configs)\n",
    "    # df = sma.get_indicator(df, '', '', 0)\n",
    "    return df\n",
    "\n",
    "def create_train_df(df, ttype, configs, target_offset, first, last, step):\n",
    "    ''' Create train dataset from signal statistics and ticker candle data'''\n",
    "    train_df = pd.DataFrame()\n",
    "    tickers = df['ticker'].unique()\n",
    "    \n",
    "    for ticker in tqdm(tickers):\n",
    "        # get signals with current ticker\n",
    "        signal_df = df[df['ticker'] == ticker]\n",
    "        times = signal_df['time']\n",
    "        \n",
    "        # load candle history of this ticker\n",
    "        tmp_df_1h, tmp_df_4h = get_file(ticker)\n",
    "\n",
    "        # add indicators \n",
    "        tmp_df_1h = add_indicators(tmp_df_1h, ttype, configs)\n",
    "\n",
    "        # add historical data for current ticker\n",
    "        for i, t in enumerate(times.to_list()):\n",
    "            pass_cycle = False\n",
    "            pattern = signal_df.iloc[i, signal_df.columns.get_loc('pattern')]\n",
    "            row = tmp_df_1h.loc[tmp_df_1h['time'] == t, :].reset_index(drop=True)\n",
    "            \n",
    "            for i in range(first, last + step, step):\n",
    "                time_prev = t + timedelta(hours= -i)\n",
    "                try:\n",
    "                    row_tmp = tmp_df_1h.loc[tmp_df_1h['time'] == time_prev, :].reset_index(drop=True)\n",
    "                    row_tmp.columns = [c + f'_prev_{i}' for c in row_tmp.columns]\n",
    "                except IndexError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                row = pd.concat([row, row_tmp.iloc[:,1:]], axis=1)\n",
    "                row['ticker'] = ticker\n",
    "                row['pattern'] = pattern\n",
    "                \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "\n",
    "            row['target'] = 0\n",
    "            \n",
    "            if row['pattern'].values == 'STOCH_RSI':\n",
    "                if ttype == 'buy':\n",
    "                    row['ttype'] = 'sell'\n",
    "                else:\n",
    "                    row['ttype'] = 'buy'\n",
    "            else:\n",
    "                row['ttype'] = ttype\n",
    "            \n",
    "            # Ff ttype = buy and during the selected period high price was higher than close_price * target_ratio\n",
    "            # and earlier low price wasn't lower than close_price / target_ratio, than target is True, else target is False.\n",
    "            # Similarly for ttype = sell \n",
    "            close_price = tmp_df_1h.loc[tmp_df_1h['time'] == t, 'close'].values\n",
    "            \n",
    "            for i in range(1, target_offset + 1):\n",
    "                time_next = t + timedelta(hours=i)\n",
    "                target_buy = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'high'].reset_index(drop=True)\n",
    "                target_sell = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'low'].reset_index(drop=True)\n",
    "\n",
    "                try:\n",
    "                    target_buy = target_buy > close_price * CFG.cls_target_ratio\n",
    "                    target_sell = target_sell < close_price / CFG.cls_target_ratio\n",
    "                except ValueError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    if (row['ttype'].values == 'buy' and target_sell[0]) or (row['ttype'].values == 'sell' and target_buy[0]):\n",
    "                        break\n",
    "                    elif (row['ttype'].values == 'buy' and target_buy[0]) or (row['ttype'].values == 'sell' and target_sell[0]):\n",
    "                        row['target'] = 1\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "            \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "\n",
    "            # add data to the dataset\n",
    "            if train_df.shape[0] == 0:\n",
    "                train_df = row\n",
    "            else:\n",
    "                train_df = pd.concat([train_df, row])\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# for how long time (in hours) we want to predict\n",
    "target_offset = 24\n",
    "# first previous data point to collect for model training (value represents number of hours before signal point)\n",
    "first = 4\n",
    "# last previous data point to collect for model training (value represents number of hours before signal point)\n",
    "last = 72\n",
    "# step of previous data points collecting (total number of points to collect is (last - first + step) / step)\n",
    "step = 4\n",
    "\n",
    "if CFG.collect_data is True:\n",
    "    # Buy\n",
    "    # dataset with the signal statistics\n",
    "    df = pd.read_pickle('signal_stat/buy_stat_1h.pkl')\n",
    "    # dataset for model train\n",
    "    train_buy = create_train_df(df, 'buy', configs, target_offset, first, last, step)\n",
    "    train_buy = train_buy.dropna()\n",
    "\n",
    "    # Sell\n",
    "    # dataset with the signal statistics\n",
    "    df = pd.read_pickle('signal_stat/sell_stat_1h.pkl')\n",
    "    # dataset for model train\n",
    "    train_sell = create_train_df(df, 'sell', configs, target_offset, first, last, step)\n",
    "    train_sell = train_sell.dropna()\n",
    "\n",
    "    train_df = pd.concat([train_buy, train_sell]).sort_values('time').reset_index(drop=True)\n",
    "    train_df.to_pickle(f'signal_stat/train_df_{last}.pkl')\n",
    "else:\n",
    "    train_df = pd.read_pickle(f'signal_stat/train_df_{last}.pkl')\n",
    "\n",
    "display(train_df.head())\n",
    "display(train_df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check target correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1000\n",
    "\n",
    "# x = train_df.loc[(train_df.target == 1) & (train_df.ttype == 'buy'), ['ticker', 'ttype', 'pattern', 'time', 'close', 'target']]\n",
    "# y = x.iloc[i]\n",
    "# low_price, high_price = y['close'] / CFG.cls_target_ratio, y['close'] * CFG.cls_target_ratio,\n",
    "# print(y['ticker'], y['time'], y['ttype'])\n",
    "\n",
    "# tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"]}_1h.pkl')\n",
    "# # tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"][:-4]}-{y[\"ticker\"][-4:]}_1h.pkl')\n",
    "# # tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"][:-4]}-{y[\"ticker\"][-4:]}-SWAP_4h.pkl')\n",
    "\n",
    "# tmp_df_1h['low_price'] = low_price\n",
    "# tmp_df_1h['high_price'] = high_price\n",
    "# idx = tmp_df_1h[tmp_df_1h['time'] == y['time']].index[0]\n",
    "\n",
    "# tmp_df_1h = tmp_df_1h.iloc[idx:idx+24][['time', 'close', 'high', 'high_price', 'low', 'low_price']]\n",
    "\n",
    "# if y['ttype'] == 'buy':\n",
    "#     tmp_df_1h['signal'] = tmp_df_1h['high'] > tmp_df_1h['high_price']\n",
    "#     tmp_df_1h['anti_signal'] = tmp_df_1h['low'] < tmp_df_1h['low_price']\n",
    "# else:\n",
    "#     tmp_df_1h['signal'] = tmp_df_1h['low'] < tmp_df_1h['low_price']\n",
    "#     tmp_df_1h['anti_signal'] = tmp_df_1h['high'] > tmp_df_1h['high_price']\n",
    "\n",
    "# tmp_df_1h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_size=0.2\n",
    "\n",
    "x_data = train_df.drop(['target', 'time', 'ticker', 'pattern', 'ttype'], axis=1)\n",
    "y_data = train_df['target'] >= train_df['close']\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=test_size, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train[x_train.columns] = scaler.fit_transform(x_train)\n",
    "x_valid[x_valid.columns] = scaler.transform(x_valid)\n",
    "\n",
    "x_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "x_valid = torch.tensor(x_valid.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.float32)\n",
    "\n",
    "display(type(x_train), type(y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find available device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find available device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigModel, self).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('lin1', torch.nn.Linear(260, 64))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('do1', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin2', torch.nn.Linear(64, 128))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('do2', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin3', torch.nn.Linear(128, 96))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('do3', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin4', torch.nn.Linear(96, 32))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('do4', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin5', torch.nn.Linear(32, 1))\n",
    "        self.layers.add_module('sigmoid', torch.nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "# train function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler):\n",
    "    # put the model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_loader\n",
    "\n",
    "    # get output of the model\n",
    "    train_preds = model(x_train).squeeze()\n",
    "    # calculate train loss\n",
    "    train_loss = criterion(train_preds, y_train)\n",
    "    train_acc = (train_preds.round() == y_train).float().mean()\n",
    "    \n",
    "    # set gradient to zero to prevent it accumulation\n",
    "    optimizer.zero_grad() # ~ model.zero_grad()\n",
    "    # calculate gradient\n",
    "    train_loss.backward() \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(x_valid).squeeze()\n",
    "        val_loss = criterion(val_preds, y_valid)\n",
    "        val_acc = (val_preds.round() == y_valid).float().mean()\n",
    "    \n",
    "    # update weights according to gradient value\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "# Initialize model\n",
    "if CFG.train_NN:\n",
    "    model = SigModel().to(device)\n",
    "\n",
    "    # Number of epochs\n",
    "    epochs = 10000\n",
    "\n",
    "    # Send data to the device\n",
    "    x_train, x_valid = x_train.to(device), x_valid.to(device)\n",
    "    y_train, y_valid = y_train.to(device), y_valid.to(device)\n",
    "    train_loader = x_train, x_valid, y_train, y_valid\n",
    "\n",
    "    # Empty loss lists to track values\n",
    "    epoch_count, train_loss_values, valid_loss_values = [], [], []\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    learning_rate = 1e-6\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2000, threshold=1e-2)\n",
    "\n",
    "    # Loop through the data\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc, val_loss, val_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "        # Print progress a total of 20 times\n",
    "        if epoch % int(epochs / 20) == 0:\n",
    "            print(f'Epoch: {epoch:4.0f} | Train Loss: {train_loss:.5f}, Train Acc: {train_acc:.5f}\\\n",
    "                Validation Loss: {val_loss:.5f}, Val Acc: {val_acc:.5f}\\\n",
    "                    LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]}')\n",
    "\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(train_loss.cpu().detach().numpy())\n",
    "            valid_loss_values.append(val_loss.cpu().detach().numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot NN train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if CFG.train_NN:\n",
    "    plt.plot(epoch_count, train_loss_values, label='Training Loss')\n",
    "    plt.plot(epoch_count, valid_loss_values, label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss Curves')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.533675\tvalid_1's binary_logloss: 0.551274\n",
      "[200]\ttraining's binary_logloss: 0.5017\tvalid_1's binary_logloss: 0.526743\n",
      "[300]\ttraining's binary_logloss: 0.463149\tvalid_1's binary_logloss: 0.498259\n",
      "[400]\ttraining's binary_logloss: 0.432549\tvalid_1's binary_logloss: 0.477228\n",
      "[500]\ttraining's binary_logloss: 0.40653\tvalid_1's binary_logloss: 0.460971\n",
      "[600]\ttraining's binary_logloss: 0.397043\tvalid_1's binary_logloss: 0.455439\n",
      "[700]\ttraining's binary_logloss: 0.382004\tvalid_1's binary_logloss: 0.447044\n",
      "[800]\ttraining's binary_logloss: 0.373078\tvalid_1's binary_logloss: 0.442644\n",
      "[900]\ttraining's binary_logloss: 0.361244\tvalid_1's binary_logloss: 0.437967\n",
      "[1000]\ttraining's binary_logloss: 0.353137\tvalid_1's binary_logloss: 0.434973\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| loss: \u001b[1m\u001b[34m0.43497\u001b[0m| Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.527683\tvalid_1's binary_logloss: 0.575327\n",
      "[200]\ttraining's binary_logloss: 0.496245\tvalid_1's binary_logloss: 0.555903\n",
      "[300]\ttraining's binary_logloss: 0.457208\tvalid_1's binary_logloss: 0.532656\n",
      "[400]\ttraining's binary_logloss: 0.425823\tvalid_1's binary_logloss: 0.515708\n",
      "[500]\ttraining's binary_logloss: 0.399018\tvalid_1's binary_logloss: 0.501342\n",
      "[600]\ttraining's binary_logloss: 0.388914\tvalid_1's binary_logloss: 0.496184\n",
      "[700]\ttraining's binary_logloss: 0.373824\tvalid_1's binary_logloss: 0.488838\n",
      "[800]\ttraining's binary_logloss: 0.364619\tvalid_1's binary_logloss: 0.484329\n",
      "[900]\ttraining's binary_logloss: 0.352683\tvalid_1's binary_logloss: 0.480066\n",
      "[1000]\ttraining's binary_logloss: 0.34488\tvalid_1's binary_logloss: 0.477952\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| loss: \u001b[1m\u001b[34m0.47795\u001b[0m| Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.535314\tvalid_1's binary_logloss: 0.544862\n",
      "[200]\ttraining's binary_logloss: 0.502936\tvalid_1's binary_logloss: 0.522266\n",
      "[300]\ttraining's binary_logloss: 0.464607\tvalid_1's binary_logloss: 0.493888\n",
      "[400]\ttraining's binary_logloss: 0.434061\tvalid_1's binary_logloss: 0.473236\n",
      "[500]\ttraining's binary_logloss: 0.407894\tvalid_1's binary_logloss: 0.456724\n",
      "[600]\ttraining's binary_logloss: 0.398344\tvalid_1's binary_logloss: 0.450771\n",
      "[700]\ttraining's binary_logloss: 0.382538\tvalid_1's binary_logloss: 0.442393\n",
      "[800]\ttraining's binary_logloss: 0.372956\tvalid_1's binary_logloss: 0.43746\n",
      "[900]\ttraining's binary_logloss: 0.360881\tvalid_1's binary_logloss: 0.43239\n",
      "[1000]\ttraining's binary_logloss: 0.353003\tvalid_1's binary_logloss: 0.429189\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| loss: \u001b[1m\u001b[34m0.42919\u001b[0m| Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.537495\tvalid_1's binary_logloss: 0.538863\n",
      "[200]\ttraining's binary_logloss: 0.504867\tvalid_1's binary_logloss: 0.513183\n",
      "[300]\ttraining's binary_logloss: 0.466759\tvalid_1's binary_logloss: 0.482057\n",
      "[400]\ttraining's binary_logloss: 0.436811\tvalid_1's binary_logloss: 0.459332\n",
      "[500]\ttraining's binary_logloss: 0.410418\tvalid_1's binary_logloss: 0.441291\n",
      "[600]\ttraining's binary_logloss: 0.400525\tvalid_1's binary_logloss: 0.435264\n",
      "[700]\ttraining's binary_logloss: 0.384711\tvalid_1's binary_logloss: 0.425932\n",
      "[800]\ttraining's binary_logloss: 0.375551\tvalid_1's binary_logloss: 0.420991\n",
      "[900]\ttraining's binary_logloss: 0.364509\tvalid_1's binary_logloss: 0.414864\n",
      "[1000]\ttraining's binary_logloss: 0.356759\tvalid_1's binary_logloss: 0.411636\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| loss: \u001b[1m\u001b[34m0.41164\u001b[0m| Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.536536\tvalid_1's binary_logloss: 0.540979\n",
      "[200]\ttraining's binary_logloss: 0.504673\tvalid_1's binary_logloss: 0.514187\n",
      "[300]\ttraining's binary_logloss: 0.466674\tvalid_1's binary_logloss: 0.483604\n",
      "[400]\ttraining's binary_logloss: 0.437056\tvalid_1's binary_logloss: 0.460467\n",
      "[500]\ttraining's binary_logloss: 0.411289\tvalid_1's binary_logloss: 0.442784\n",
      "[600]\ttraining's binary_logloss: 0.401685\tvalid_1's binary_logloss: 0.436312\n",
      "[700]\ttraining's binary_logloss: 0.387098\tvalid_1's binary_logloss: 0.426986\n",
      "[800]\ttraining's binary_logloss: 0.377713\tvalid_1's binary_logloss: 0.422134\n",
      "[900]\ttraining's binary_logloss: 0.366063\tvalid_1's binary_logloss: 0.416405\n",
      "[1000]\ttraining's binary_logloss: 0.357594\tvalid_1's binary_logloss: 0.413312\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| loss: \u001b[1m\u001b[34m0.41331\u001b[0m| Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n",
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m Outer Holdout avg score: \u001b[0m log_loss: \u001b[1m\u001b[31m0.43357\u001b[0m\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "def lgbm_tuning(df, permut=False, boruta=False):\n",
    "    features = [c for c in df.columns if c not in ['time', 'target', 'ticker', 'pattern', 'ttype']]\n",
    "    groups = df['ticker']\n",
    "\n",
    "    outer_cv_score = [] # store all cv scores of outer loop inference\n",
    "\n",
    "    perm_df_ = pd.DataFrame()\n",
    "    feature_importances_ = pd.DataFrame()\n",
    "    boruta_df_ = pd.DataFrame()\n",
    "    \n",
    "    for i in range(CFG.n_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "        \n",
    "        if task_type == 'cls':\n",
    "            y_fold = df['target'] >= df['close']\n",
    "            kf = StratifiedGroupKFold(n_splits=CFG.n_folds, shuffle=True, random_state=180820231)\n",
    "            eval_metric = 'logloss'\n",
    "        else:\n",
    "            y_fold = (df['target'] - df['close']) / df['close']\n",
    "            kf = GroupKFold(n_splits=CFG.n_folds)\n",
    "            eval_metric = 'mse'\n",
    "\n",
    "        X, y = df[features], y_fold\n",
    "        oof = np.zeros(len(df))\n",
    "        models_ = [] # Used to store models trained in the inner loop.\n",
    "        \n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y, groups)):\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            if task_type == 'cls':\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "            else:\n",
    "                clf = lgb.LGBMRegressor(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                    eval_metric=eval_metric, \n",
    "                    callbacks=[lgb.log_evaluation(100)])\n",
    "\n",
    "            models_.append(clf)\n",
    "\n",
    "            if task_type == 'cls':\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                val_score = log_loss(y_val, val_preds)\n",
    "            else:\n",
    "                val_preds = clf.predict(X_val)\n",
    "                val_score = mean_squared_error(y_val, val_preds, squared=False)\n",
    "            \n",
    "            oof[val_idx] = val_preds\n",
    "            best_iter = clf.best_iteration_\n",
    "\n",
    "            print(f'Fold: {blu}{fold + 1:>3}{res}| loss: {blu}{val_score:.5f}{res}| Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "            # permutation importance\n",
    "            if permut:\n",
    "                perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                             random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                    index=X_val.columns).sort_index()\n",
    "\n",
    "                if perm_df_.shape[0] == 0:\n",
    "                    perm_df_ = perm_importance_df.copy()\n",
    "                else:\n",
    "                    perm_df_ += perm_importance_df\n",
    "\n",
    "            # gboost feature importance\n",
    "            f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                      reverse=True, key=lambda x: x[1]), \n",
    "                                columns=['Value','Feature'])\n",
    "\n",
    "            if feature_importances_.shape[0] == 0:\n",
    "                feature_importances_ = f_i.copy()\n",
    "            else:\n",
    "                feature_importances_['Value'] += f_i['Value']\n",
    "                    \n",
    "            # BORUTA importance\n",
    "            if boruta:\n",
    "                model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                try:\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                            eval_metric=eval_metric, \n",
    "                            callbacks=[lgb.log_evaluation(100)])\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "                \n",
    "                boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                        index=X_train.columns).sort_index()\n",
    "                if boruta_df_.shape[0] == 0:\n",
    "                    boruta_df_ = boruta_importance_df.copy()\n",
    "                else:\n",
    "                    boruta_df_ += boruta_importance_df\n",
    "\n",
    "        if task_type == 'cls':\n",
    "            outer_cv = log_loss(y, oof)\n",
    "        else:\n",
    "            outer_cv = mean_squared_error(y, oof, squared=False)\n",
    "        \n",
    "        outer_cv_score.append(outer_cv)\n",
    "\n",
    "    print(f'{red} Outer Holdout avg score: {res} log_loss: {red}{np.mean(outer_cv_score):.5f}{res}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    \n",
    "    if permut:\n",
    "        perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "        perm_df_ = perm_df_.reset_index().rename({'index': 'Feature'}, axis=1)\n",
    "        \n",
    "    if boruta:\n",
    "        boruta_df_ = boruta_df_.sort_values('importance')\n",
    "        boruta_df_ = boruta_df_.reset_index().rename({'index': 'Feature'}, axis=1)\n",
    "                                    \n",
    "    feature_importances_ = feature_importances_.sort_values('Value', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return perm_df_, feature_importances_, boruta_df_, np.mean(outer_cv_score)\n",
    "\n",
    "\n",
    "params = {\n",
    "          'n_estimators': 1000,\n",
    "          'learning_rate': 0.01,\n",
    "        #   'early_stopping_round': 100,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "          'max_depth': 7,\n",
    "          'subsample' : 0.8,\n",
    "          'colsample_bytree': 0.75,\n",
    "          'num_leaves': 32,\n",
    "          'verbosity': -1,\n",
    "          'importance_type': 'gain'\n",
    "        }\n",
    "\n",
    "task_type = 'cls'\n",
    "\n",
    "if task_type == 'cls':\n",
    "    params['boosting_type'] = 'dart'\n",
    "    params['objective'] = 'binary'\n",
    "else:\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'regression'\n",
    "\n",
    "if CFG.select_features:\n",
    "    perm_df_, feature_importances_, boruta_df_, outer_cv_score = lgbm_tuning(train_df, permut=True, boruta=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine importances and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features:\n",
    "    perm_df_['rank'] = perm_df_['importance'].rank(ascending=False)\n",
    "    boruta_df_['rank'] = boruta_df_['importance'].rank()\n",
    "    feature_importances_['rank'] = feature_importances_['Value'].rank(ascending=False)\n",
    "\n",
    "    res = pd.concat([perm_df_[['Feature','rank']], boruta_df_[['Feature','rank']], feature_importances_[['Feature','rank']]])\n",
    "    res = res.groupby('Feature')['rank'].sum().sort_values()\n",
    "    res.to_csv('feature_importance.csv')\n",
    "else:\n",
    "    res = pd.read_csv('feature_importance.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 150 features\n",
      "Fold #1\n",
      "[100]\tvalid_0's binary_logloss: 0.67991\tvalid_0's average_precision: 0.62238\n",
      "[200]\tvalid_0's binary_logloss: 0.67665\tvalid_0's average_precision: 0.623962\n",
      "[300]\tvalid_0's binary_logloss: 0.673577\tvalid_0's average_precision: 0.625737\n",
      "[400]\tvalid_0's binary_logloss: 0.671554\tvalid_0's average_precision: 0.628079\n",
      "[500]\tvalid_0's binary_logloss: 0.671037\tvalid_0's average_precision: 0.627665\n",
      "[600]\tvalid_0's binary_logloss: 0.670899\tvalid_0's average_precision: 0.627498\n",
      "[700]\tvalid_0's binary_logloss: 0.671233\tvalid_0's average_precision: 0.622484\n",
      "[800]\tvalid_0's binary_logloss: 0.670949\tvalid_0's average_precision: 0.62298\n",
      "[900]\tvalid_0's binary_logloss: 0.669803\tvalid_0's average_precision: 0.625105\n",
      "[1000]\tvalid_0's binary_logloss: 0.669142\tvalid_0's average_precision: 0.625675\n",
      "[1100]\tvalid_0's binary_logloss: 0.668517\tvalid_0's average_precision: 0.62852\n",
      "[1200]\tvalid_0's binary_logloss: 0.66745\tvalid_0's average_precision: 0.632921\n",
      "[1300]\tvalid_0's binary_logloss: 0.667207\tvalid_0's average_precision: 0.634166\n",
      "[1400]\tvalid_0's binary_logloss: 0.665847\tvalid_0's average_precision: 0.638334\n",
      "[1500]\tvalid_0's binary_logloss: 0.665276\tvalid_0's average_precision: 0.640471\n",
      "[1600]\tvalid_0's binary_logloss: 0.665113\tvalid_0's average_precision: 0.641265\n",
      "[1700]\tvalid_0's binary_logloss: 0.665433\tvalid_0's average_precision: 0.640205\n",
      "[1800]\tvalid_0's binary_logloss: 0.665079\tvalid_0's average_precision: 0.640835\n",
      "[1900]\tvalid_0's binary_logloss: 0.665549\tvalid_0's average_precision: 0.638058\n",
      "Logloss: 0.6655487954414756, Confident objects precision: 0.7046979865771812, % of confident objects: 0.16944655041698256\n",
      "Fold #2\n",
      "[100]\tvalid_0's binary_logloss: 0.680549\tvalid_0's average_precision: 0.604584\n",
      "[200]\tvalid_0's binary_logloss: 0.677109\tvalid_0's average_precision: 0.608443\n",
      "[300]\tvalid_0's binary_logloss: 0.673911\tvalid_0's average_precision: 0.612901\n",
      "[400]\tvalid_0's binary_logloss: 0.671353\tvalid_0's average_precision: 0.617914\n",
      "[500]\tvalid_0's binary_logloss: 0.669529\tvalid_0's average_precision: 0.623663\n",
      "[600]\tvalid_0's binary_logloss: 0.669265\tvalid_0's average_precision: 0.624164\n",
      "[700]\tvalid_0's binary_logloss: 0.668013\tvalid_0's average_precision: 0.627017\n",
      "[800]\tvalid_0's binary_logloss: 0.66606\tvalid_0's average_precision: 0.63295\n",
      "[900]\tvalid_0's binary_logloss: 0.664983\tvalid_0's average_precision: 0.634827\n",
      "[1000]\tvalid_0's binary_logloss: 0.663873\tvalid_0's average_precision: 0.639997\n",
      "[1100]\tvalid_0's binary_logloss: 0.661824\tvalid_0's average_precision: 0.643466\n",
      "[1200]\tvalid_0's binary_logloss: 0.662081\tvalid_0's average_precision: 0.643501\n",
      "[1300]\tvalid_0's binary_logloss: 0.661785\tvalid_0's average_precision: 0.642929\n",
      "[1400]\tvalid_0's binary_logloss: 0.660755\tvalid_0's average_precision: 0.64544\n",
      "[1500]\tvalid_0's binary_logloss: 0.660251\tvalid_0's average_precision: 0.646199\n",
      "[1600]\tvalid_0's binary_logloss: 0.659533\tvalid_0's average_precision: 0.648182\n",
      "[1700]\tvalid_0's binary_logloss: 0.659112\tvalid_0's average_precision: 0.649014\n",
      "[1800]\tvalid_0's binary_logloss: 0.659172\tvalid_0's average_precision: 0.647763\n",
      "[1900]\tvalid_0's binary_logloss: 0.658475\tvalid_0's average_precision: 0.649875\n",
      "Logloss: 0.6584747673627855, Confident objects precision: 0.7019230769230769, % of confident objects: 0.20783373301358912\n",
      "Fold #3\n",
      "[100]\tvalid_0's binary_logloss: 0.681121\tvalid_0's average_precision: 0.606175\n",
      "[200]\tvalid_0's binary_logloss: 0.677356\tvalid_0's average_precision: 0.609641\n",
      "[300]\tvalid_0's binary_logloss: 0.67378\tvalid_0's average_precision: 0.617335\n",
      "[400]\tvalid_0's binary_logloss: 0.671566\tvalid_0's average_precision: 0.621268\n",
      "[500]\tvalid_0's binary_logloss: 0.669491\tvalid_0's average_precision: 0.625703\n",
      "[600]\tvalid_0's binary_logloss: 0.670276\tvalid_0's average_precision: 0.622661\n",
      "[700]\tvalid_0's binary_logloss: 0.669123\tvalid_0's average_precision: 0.622547\n",
      "[800]\tvalid_0's binary_logloss: 0.668591\tvalid_0's average_precision: 0.623877\n",
      "[900]\tvalid_0's binary_logloss: 0.66797\tvalid_0's average_precision: 0.623627\n",
      "[1000]\tvalid_0's binary_logloss: 0.668301\tvalid_0's average_precision: 0.622443\n",
      "[1100]\tvalid_0's binary_logloss: 0.667437\tvalid_0's average_precision: 0.621562\n",
      "[1200]\tvalid_0's binary_logloss: 0.667704\tvalid_0's average_precision: 0.621728\n",
      "[1300]\tvalid_0's binary_logloss: 0.66753\tvalid_0's average_precision: 0.621757\n",
      "[1400]\tvalid_0's binary_logloss: 0.667331\tvalid_0's average_precision: 0.622348\n",
      "[1500]\tvalid_0's binary_logloss: 0.666737\tvalid_0's average_precision: 0.624441\n",
      "[1600]\tvalid_0's binary_logloss: 0.66742\tvalid_0's average_precision: 0.622127\n",
      "[1700]\tvalid_0's binary_logloss: 0.667061\tvalid_0's average_precision: 0.623039\n",
      "[1800]\tvalid_0's binary_logloss: 0.667476\tvalid_0's average_precision: 0.621226\n",
      "[1900]\tvalid_0's binary_logloss: 0.667752\tvalid_0's average_precision: 0.622242\n",
      "Logloss: 0.667752067639035, Confident objects precision: 0.7012578616352201, % of confident objects: 0.17453347969264543\n",
      "Fold #4\n",
      "[100]\tvalid_0's binary_logloss: 0.6748\tvalid_0's average_precision: 0.670242\n",
      "[200]\tvalid_0's binary_logloss: 0.668981\tvalid_0's average_precision: 0.67745\n",
      "[300]\tvalid_0's binary_logloss: 0.664103\tvalid_0's average_precision: 0.681859\n",
      "[400]\tvalid_0's binary_logloss: 0.661238\tvalid_0's average_precision: 0.689018\n",
      "[500]\tvalid_0's binary_logloss: 0.657675\tvalid_0's average_precision: 0.69485\n",
      "[600]\tvalid_0's binary_logloss: 0.658208\tvalid_0's average_precision: 0.693555\n",
      "[700]\tvalid_0's binary_logloss: 0.656318\tvalid_0's average_precision: 0.691597\n",
      "[800]\tvalid_0's binary_logloss: 0.655386\tvalid_0's average_precision: 0.694991\n",
      "[900]\tvalid_0's binary_logloss: 0.654\tvalid_0's average_precision: 0.693407\n",
      "[1000]\tvalid_0's binary_logloss: 0.652854\tvalid_0's average_precision: 0.695394\n",
      "[1100]\tvalid_0's binary_logloss: 0.65179\tvalid_0's average_precision: 0.69919\n",
      "[1200]\tvalid_0's binary_logloss: 0.650787\tvalid_0's average_precision: 0.701198\n",
      "[1300]\tvalid_0's binary_logloss: 0.649217\tvalid_0's average_precision: 0.703663\n",
      "[1400]\tvalid_0's binary_logloss: 0.647683\tvalid_0's average_precision: 0.704575\n",
      "[1500]\tvalid_0's binary_logloss: 0.648379\tvalid_0's average_precision: 0.702229\n",
      "[1600]\tvalid_0's binary_logloss: 0.646718\tvalid_0's average_precision: 0.705739\n",
      "[1700]\tvalid_0's binary_logloss: 0.645629\tvalid_0's average_precision: 0.706618\n",
      "[1800]\tvalid_0's binary_logloss: 0.644555\tvalid_0's average_precision: 0.708607\n",
      "[1900]\tvalid_0's binary_logloss: 0.643849\tvalid_0's average_precision: 0.708278\n",
      "Logloss: 0.6438491201008107, Confident objects precision: 0.783068783068783, % of confident objects: 0.17838603114676735\n",
      "Fold #5\n",
      "[100]\tvalid_0's binary_logloss: 0.676331\tvalid_0's average_precision: 0.652565\n",
      "[200]\tvalid_0's binary_logloss: 0.671804\tvalid_0's average_precision: 0.656245\n",
      "[300]\tvalid_0's binary_logloss: 0.667661\tvalid_0's average_precision: 0.65827\n",
      "[400]\tvalid_0's binary_logloss: 0.665388\tvalid_0's average_precision: 0.657734\n",
      "[500]\tvalid_0's binary_logloss: 0.663287\tvalid_0's average_precision: 0.662091\n",
      "[600]\tvalid_0's binary_logloss: 0.66259\tvalid_0's average_precision: 0.661811\n",
      "[700]\tvalid_0's binary_logloss: 0.661523\tvalid_0's average_precision: 0.661065\n",
      "[800]\tvalid_0's binary_logloss: 0.660631\tvalid_0's average_precision: 0.662128\n",
      "[900]\tvalid_0's binary_logloss: 0.658859\tvalid_0's average_precision: 0.664838\n",
      "[1000]\tvalid_0's binary_logloss: 0.658142\tvalid_0's average_precision: 0.665817\n",
      "[1100]\tvalid_0's binary_logloss: 0.658096\tvalid_0's average_precision: 0.665213\n",
      "[1200]\tvalid_0's binary_logloss: 0.657188\tvalid_0's average_precision: 0.666938\n",
      "[1300]\tvalid_0's binary_logloss: 0.657332\tvalid_0's average_precision: 0.664699\n",
      "[1400]\tvalid_0's binary_logloss: 0.656547\tvalid_0's average_precision: 0.665054\n",
      "[1500]\tvalid_0's binary_logloss: 0.655979\tvalid_0's average_precision: 0.666841\n",
      "[1600]\tvalid_0's binary_logloss: 0.655544\tvalid_0's average_precision: 0.667156\n",
      "[1700]\tvalid_0's binary_logloss: 0.655158\tvalid_0's average_precision: 0.668071\n",
      "[1800]\tvalid_0's binary_logloss: 0.655265\tvalid_0's average_precision: 0.66834\n",
      "[1900]\tvalid_0's binary_logloss: 0.655442\tvalid_0's average_precision: 0.667096\n",
      "Logloss: 0.6554420977480441, Confident objects precision: 0.7304582210242587, % of confident objects: 0.14722222222222223\n",
      "Total Logloss: 0.6582101740689003, Total confident objects precision: 0.7227138643067846, Total % of confident objects: 0.17532971295577968\n"
     ]
    }
   ],
   "source": [
    "def model_train(df, features, task_type, how, n_folds, low_bound, high_bound): \n",
    "    oof = np.zeros([df['target'].shape[0], 1])\n",
    "\n",
    "    X, groups = df[features], df['ticker']\n",
    "    X = pd.concat([X, pd.get_dummies(df['pattern'], drop_first=True)], axis=1)\n",
    "    # X = pd.concat([X, pd.get_dummies(df['ttype'], drop_first=True)], axis=1)\n",
    "    \n",
    "    if task_type == 'cls':\n",
    "        y = df['target']\n",
    "        kf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=180820231)\n",
    "    else:\n",
    "        y = (df['target'] - df['close']) / df['close']\n",
    "        kf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "    oe_enc = OrdinalEncoder()\n",
    "    groups = oe_enc.fit_transform(groups.values.reshape(-1, 1))\n",
    "\n",
    "    print(f\"Training with {len(features)} features\")\n",
    "    \n",
    "    if how == 'lreg':\n",
    "        scaler = StandardScaler()\n",
    "        X[X.columns] = scaler.fit_transform(X)\n",
    "    \n",
    "    for fold, (fit_idx, val_idx) in enumerate(kf.split(X, y, groups)):\n",
    "        print(f'Fold #{fold + 1}')\n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        models = list()\n",
    "        if how == 'lgbm':\n",
    "            if task_type == 'cls':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                        eval_metric='logloss', callbacks = [lgb.log_evaluation(100)])\n",
    "                # best_iter = model.best_iteration_\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                        eval_metric='mse', callbacks = [lgb.log_evaluation(100)])\n",
    "                # best_iter = model.best_iteration_\n",
    "        elif how == 'lreg':\n",
    "            if task_type == 'cls':\n",
    "                model = LogisticRegression(C=0.1, max_iter=100000)#, class_weight='balanced')\n",
    "                model.fit(X_train, y_train)\n",
    "            else:\n",
    "                model = LinearRegression(positive=True)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "        if task_type == 'cls':\n",
    "            val_preds = model.predict_proba(X_val)\n",
    "            val_score = log_loss(y_val, val_preds)\n",
    "            prec_score, prec_obj_pct = confident_score(y_val, val_preds[:,1], low_bound, high_bound)\n",
    "            print(f'Logloss: {val_score}, Confident objects precision: {prec_score}, % of confident objects: {prec_obj_pct}')\n",
    "            oof[val_idx, 0] = val_preds[:,1]\n",
    "        else:\n",
    "            val_preds = model.predict(X_val)\n",
    "            val_score = mean_squared_error(y_val, val_preds, squared=False)\n",
    "            print('RMSE: {val_score}')\n",
    "            oof[val_idx, 0] = val_preds\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "    return oof, models\n",
    "\n",
    "def confident_score(y, oof, low_bound, high_bound):\n",
    "    ''' Consider only high confident objects for accuracy and precision scores calculation;\n",
    "        object probability must be lower than low_bound or higher than high_bound '''\n",
    "    pred_conf = np.zeros_like(oof)\n",
    "    pred_conf[oof > high_bound] = 1\n",
    "    pred_conf[oof < low_bound] = 0\n",
    "    pred_conf_acc = pred_conf[(oof < low_bound) | (oof > high_bound)]\n",
    "    pred_conf_prec = pred_conf[(oof > high_bound)]\n",
    "\n",
    "    y_conf_acc = y.values.reshape(-1,1)[(oof < low_bound) | (oof > high_bound)]\n",
    "    y_conf_prec = y.values.reshape(-1,1)[(oof > high_bound)]\n",
    "\n",
    "    return precision_score(y_conf_prec, pred_conf_prec), y_conf_prec.shape[0]/y.shape[0]\n",
    "\n",
    "# task_type = 'reg'\n",
    "task_type = 'cls'\n",
    "\n",
    "# best params for classification\n",
    "if task_type == 'cls':\n",
    "    params = {\n",
    "        'boosting_type': 'dart',\n",
    "        'n_estimators': 1900,\n",
    "        'learning_rate': 0.02,\n",
    "        #   'early_stopping_round': 50,\n",
    "        'max_depth': 10,\n",
    "        'colsample_bytree': 0.65,\n",
    "        'subsample': 0.8,\n",
    "        'subsample_freq': 1,\n",
    "        'num_leaves': 24,\n",
    "        'verbosity': -1,\n",
    "        'max_bin': 255,\n",
    "        'reg_alpha': 1e-6,\n",
    "        'reg_lambda': 1e-8,\n",
    "        'objective': 'binary',\n",
    "        # 'is_unbalance': True,\n",
    "        # 'class_weight': 'balanced',\n",
    "        'metric': 'average_precision'\n",
    "        }\n",
    "else:\n",
    "    # best params for regression\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'n_estimators': 1000,\n",
    "            'learning_rate': 0.021,\n",
    "            'early_stopping_round': 100,\n",
    "            'max_depth': 7,\n",
    "            'colsample_bytree': 0.75,\n",
    "            'subsample': 0.8,\n",
    "            'subsample_freq': 1,\n",
    "            'num_leaves': 27,\n",
    "            'verbosity': -1,\n",
    "            'max_bin': 511,\n",
    "            'reg_alpha': 1e-4,\n",
    "            'reg_lambda': 1e-4,\n",
    "            'objective': 'regression'\n",
    "            }\n",
    "\n",
    "if CFG.train_LGBM:\n",
    "    low_bound, high_bound = 0.38, 0.62\n",
    "    features = res.head(150).index.to_list()\n",
    "    oof, models = model_train(train_df, features, task_type=task_type, how='lgbm', n_folds=5, low_bound=low_bound, high_bound=high_bound)\n",
    "\n",
    "    if task_type == 'cls':\n",
    "        y = train_df['target']\n",
    "        oof_val_score = log_loss(y, oof)\n",
    "        oof_conf_prec_score, oof_conf_obj_pct = confident_score(y, oof, low_bound, high_bound)\n",
    "        print(f'Total Logloss: {oof_val_score}, Total confident objects precision: {oof_conf_prec_score}, Total % of confident objects: {oof_conf_obj_pct}')\n",
    "    else:\n",
    "        y = (train_df['target'] - train_df['close']) / train_df['close']\n",
    "        display(mean_squared_error(y, oof, squared=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Logloss: 0.6582101740689003, Total confident objects precision: 0.7227138643067846, Total % of confident objects: 0.17532971295577968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features = list()\n",
    "low_bound, high_bound = 0.4, 0.6\n",
    "features = res.groupby('Feature')['rank'].sum().sort_values().head(150).index.to_list()\n",
    "oof, models = model_train(train_df, features, task_type=task_type, how='lgbm', n_folds=5, low_bound=low_bound, high_bound=high_bound)\n",
    "baseline_prec, baseline_pct = confident_score(y, oof, low_bound, high_bound)\n",
    "print(f'Total confident objects precision: {baseline_prec}')\n",
    "\n",
    "for feat in tqdm(features[30:]):\n",
    "    tmp_features = [f for f in features if f != feat]\n",
    "    oof, models = model_train(train_df, features, task_type=task_type, how='lgbm', n_folds=5, low_bound=low_bound, high_bound=high_bound)\n",
    "    prec_score, pct = confident_score(y, oof, low_bound, high_bound)\n",
    "    print(f'Feature: {feat}, Total precision: {prec_score}, Baseline precision: {baseline_prec}, Total pct: {pct}, Baseline precision: {baseline_pct}')\n",
    "    if prec_score > baseline_prec and pct > baseline_pct:\n",
    "        \n",
    "        bad_features.append(feat)\n",
    "        print(bad_features)\n",
    "\n",
    "bad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volume_prev_8']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150: Total Logloss: 0.6079201456679827, Total confident objects precision: 0.7093922651933702, Total % of confident objects: 0.07814523788964683"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
