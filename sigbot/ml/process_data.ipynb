{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and add indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [00:56<00:00,  6.54it/s]\n",
      "100%|██████████| 308/308 [00:30<00:00, 10.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stoch_slowk</th>\n",
       "      <th>stoch_slowd</th>\n",
       "      <th>stoch_slowk_dir</th>\n",
       "      <th>...</th>\n",
       "      <th>linear_reg_prev_10</th>\n",
       "      <th>linear_reg_angle_prev_10</th>\n",
       "      <th>macd_prev_10</th>\n",
       "      <th>macdsignal_prev_10</th>\n",
       "      <th>macdhist_prev_10</th>\n",
       "      <th>macd_dir_prev_10</th>\n",
       "      <th>macdsignal_dir_prev_10</th>\n",
       "      <th>atr_prev_10</th>\n",
       "      <th>close_smooth_prev_10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23 07:00:00</td>\n",
       "      <td>1.07400</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.073000</td>\n",
       "      <td>1.085000</td>\n",
       "      <td>3.103127e+05</td>\n",
       "      <td>65.341348</td>\n",
       "      <td>85.293979</td>\n",
       "      <td>87.119652</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>...</td>\n",
       "      <td>29.684219</td>\n",
       "      <td>-15.006676</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.004305</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>0.159254</td>\n",
       "      <td>0.135557</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>1.041250</td>\n",
       "      <td>1.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-23 07:00:00</td>\n",
       "      <td>0.69300</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>5.163977e+05</td>\n",
       "      <td>81.721385</td>\n",
       "      <td>85.531532</td>\n",
       "      <td>83.150654</td>\n",
       "      <td>0.067481</td>\n",
       "      <td>...</td>\n",
       "      <td>10.538362</td>\n",
       "      <td>-4.140549</td>\n",
       "      <td>-0.014886</td>\n",
       "      <td>-0.015304</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010925</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.678750</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-23 19:00:00</td>\n",
       "      <td>0.05791</td>\n",
       "      <td>0.058277</td>\n",
       "      <td>0.057680</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>3.959650e+05</td>\n",
       "      <td>40.206455</td>\n",
       "      <td>18.989544</td>\n",
       "      <td>16.812634</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>...</td>\n",
       "      <td>50.557651</td>\n",
       "      <td>-3.492108</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>-0.001134</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065048</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.059634</td>\n",
       "      <td>0.056878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-23 23:00:00</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>1.104384e+07</td>\n",
       "      <td>26.198774</td>\n",
       "      <td>8.825903</td>\n",
       "      <td>9.923913</td>\n",
       "      <td>0.045659</td>\n",
       "      <td>...</td>\n",
       "      <td>31.974021</td>\n",
       "      <td>-11.381398</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.063876</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.002773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-24 03:00:00</td>\n",
       "      <td>0.43000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>4.920985e+04</td>\n",
       "      <td>44.025328</td>\n",
       "      <td>17.388802</td>\n",
       "      <td>12.184720</td>\n",
       "      <td>0.235390</td>\n",
       "      <td>...</td>\n",
       "      <td>14.829397</td>\n",
       "      <td>-7.155657</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.122295</td>\n",
       "      <td>1.215276</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.436750</td>\n",
       "      <td>0.426000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time     open      high       low     close        volume  \\\n",
       "0 2022-12-23 07:00:00  1.07400  1.100000  1.073000  1.085000  3.103127e+05   \n",
       "1 2022-12-23 07:00:00  0.69300  0.777000  0.691000  0.768000  5.163977e+05   \n",
       "2 2022-12-23 19:00:00  0.05791  0.058277  0.057680  0.058167  3.959650e+05   \n",
       "3 2022-12-23 23:00:00  0.00272  0.002720  0.002702  0.002712  1.104384e+07   \n",
       "4 2022-12-24 03:00:00  0.43000  0.433000  0.430000  0.433000  4.920985e+04   \n",
       "\n",
       "         rsi  stoch_slowk  stoch_slowd  stoch_slowk_dir  ...  \\\n",
       "0  65.341348    85.293979    87.119652         0.026489  ...   \n",
       "1  81.721385    85.531532    83.150654         0.067481  ...   \n",
       "2  40.206455    18.989544    16.812634         0.026486  ...   \n",
       "3  26.198774     8.825903     9.923913         0.045659  ...   \n",
       "4  44.025328    17.388802    12.184720         0.235390  ...   \n",
       "\n",
       "   linear_reg_prev_10  linear_reg_angle_prev_10  macd_prev_10  \\\n",
       "0           29.684219                -15.006676     -0.006157   \n",
       "1           10.538362                 -4.140549     -0.014886   \n",
       "2           50.557651                 -3.492108     -0.000819   \n",
       "3           31.974021                -11.381398     -0.000015   \n",
       "4           14.829397                 -7.155657      0.000279   \n",
       "\n",
       "   macdsignal_prev_10  macdhist_prev_10  macd_dir_prev_10  \\\n",
       "0           -0.004305         -0.001852          0.159254   \n",
       "1           -0.015304          0.000418          0.000000   \n",
       "2           -0.001134          0.000315          0.000000   \n",
       "3           -0.000022          0.000006          0.000000   \n",
       "4            0.000208          0.000071         -0.122295   \n",
       "\n",
       "   macdsignal_dir_prev_10  atr_prev_10  close_smooth_prev_10    target  \n",
       "0                0.135557     0.010157              1.041250  1.086000  \n",
       "1               -0.010925     0.014147              0.678750  0.730000  \n",
       "2               -0.065048     0.001013              0.059634  0.056878  \n",
       "3               -0.063876     0.000021              0.002841  0.002773  \n",
       "4                1.215276     0.004542              0.436750  0.426000  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5484, 224)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from os import environ\n",
    "import pandas as pd\n",
    "from indicators import indicators\n",
    "from datetime import timedelta\n",
    "from tqdm.auto import tqdm\n",
    "from config.config import ConfigFactory\n",
    "\n",
    "# Set environment variable\n",
    "environ[\"ENV\"] = \"1h_4h\"\n",
    "\n",
    "# Get configs\n",
    "configs = ConfigFactory.factory(environ).configs\n",
    "\n",
    "def get_file(ticker):\n",
    "    ''' Find files buy ticker names, file names can be in different formats '''\n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def add_indicators(df, ttype, configs):\n",
    "    # add RSI\n",
    "    rsi = indicators.RSI(ttype, configs)\n",
    "    df = rsi.get_indicator(df, '', '', 0)\n",
    "    # add RSI\n",
    "    stoch = indicators.STOCH(ttype, configs)\n",
    "    df = stoch.get_indicator(df, '', '', 0)\n",
    "    # add Trend\n",
    "    trend = indicators.Trend(ttype, configs)\n",
    "    df = trend.get_indicator(df, '', '', 0)\n",
    "    # add MACD\n",
    "    macd = indicators.MACD(ttype, configs)\n",
    "    df = macd.get_indicator(df, '', '', 0)\n",
    "    # add ATR\n",
    "    atr = indicators.ATR(ttype, configs)\n",
    "    df = atr.get_indicator(df, '', '', 0)\n",
    "    return df\n",
    "\n",
    "def create_train_df(df, ttype, configs, target_offset, first, last, step):\n",
    "    ''' Create train dataset from signal statistics and ticker candle data'''\n",
    "    train_df = pd.DataFrame()\n",
    "    tickers = df['ticker'].unique()\n",
    "    \n",
    "    for ticker in tqdm(tickers):\n",
    "        # get signals with current ticker\n",
    "        signal_df = df[df['ticker'] == ticker]\n",
    "        times = signal_df['time']\n",
    "        \n",
    "        # load candle history of this ticker\n",
    "        tmp_df_1h, tmp_df_4h = get_file(ticker)\n",
    "\n",
    "        # add indicators \n",
    "        tmp_df_1h = add_indicators(tmp_df_1h, ttype, configs)\n",
    "\n",
    "        # add historical data for current ticker\n",
    "        for i, t in enumerate(times.to_list()):\n",
    "            pass_cycle = False\n",
    "            pattern = signal_df.iloc[i, signal_df.columns.get_loc('pattern')]\n",
    "            row = tmp_df_1h.loc[tmp_df_1h['time'] == t, :].reset_index(drop=True)\n",
    "            \n",
    "            for i in range(first, last + step, step):\n",
    "                time_prev = t + timedelta(hours= -i)\n",
    "                try:\n",
    "                    row_tmp = tmp_df_1h.loc[tmp_df_1h['time'] == time_prev, :].reset_index(drop=True)\n",
    "                    row_tmp.columns = [c + f'_prev_{i}' for c in row_tmp.columns]\n",
    "                except IndexError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                row = pd.concat([row, row_tmp.iloc[:,1:]], axis=1)\n",
    "                row['ticker'] = ticker\n",
    "                row['pattern'] = pattern\n",
    "                \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "            \n",
    "            # add target\n",
    "            time_next = t + timedelta(hours=target_offset)\n",
    "            if ttype == 'buy':\n",
    "                target = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'high'].reset_index(drop=True)\n",
    "            else:\n",
    "                target = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'low'].reset_index(drop=True)\n",
    "\n",
    "            target.name = 'target'\n",
    "            rows = pd.concat([row, target], axis=1)\n",
    "            \n",
    "            # add data to the dataset\n",
    "            if train_df.shape[0] == 0:\n",
    "                train_df = rows\n",
    "            else:\n",
    "                train_df = pd.concat([train_df, rows])\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# for how long time (in hours) we want to predict\n",
    "target_offset = 24\n",
    "# first previous data point to collect for model training (value represents number of hours before signal point)\n",
    "first = 1\n",
    "# last previous data point to collect for model training (value represents number of hours before signal point)\n",
    "last = 10\n",
    "# step of previous data points collecting (total number of points to collect is (last - first + step) / step)\n",
    "step = 1\n",
    "\n",
    "# Buy\n",
    "# dataset with the signal statistics\n",
    "df = pd.read_pickle('signal_stat/buy_stat_1h.pkl')\n",
    "# dataset for model train\n",
    "train_buy = create_train_df(df, 'buy', configs, target_offset, first, last, step)\n",
    "train_buy = train_buy.dropna()\n",
    "\n",
    "# Sell\n",
    "# dataset with the signal statistics\n",
    "df = pd.read_pickle('signal_stat/sell_stat_1h.pkl')\n",
    "# dataset for model train\n",
    "train_sell = create_train_df(df, 'sell', configs, target_offset, first, last, step)\n",
    "train_sell = train_sell.dropna()\n",
    "\n",
    "train_df = pd.concat([train_buy, train_sell]).sort_values('time').reset_index(drop=True)\n",
    "display(train_df.head())\n",
    "display(train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 220 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.411732392116155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4616621852036131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4583476779843323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3988915366877706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4348487278787105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4339585802642052"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "params = {\n",
    "          'objective': 'multiclass',\n",
    "        #   'metric': 'multi_logloss',\n",
    "          'n_estimators': 2000,\n",
    "          'learning_rate': 0.11,\n",
    "          'early_stopping_round': 50,\n",
    "          'max_depth': 9\n",
    "        }\n",
    "\n",
    "\n",
    "def model_train(df, how, n_folds, stratified): \n",
    "    oof = np.zeros([df['target'].shape[0], 5])\n",
    "    features = [c for c in df.columns if c not in ['time', 'target', 'ticker', 'pattern']]\n",
    "    X, groups = df[features], df['ticker']\n",
    "    X = pd.concat([X, pd.get_dummies(train_df['pattern'], drop_first=True)], axis=1)\n",
    "    y = np.clip(np.round((train_df['target'] - train_df['close']) / train_df['close'] * 100, 0), -2, 2) + 2\n",
    "    \n",
    "    oe_enc = OrdinalEncoder()\n",
    "    groups = oe_enc.fit_transform(groups.values.reshape(-1, 1))\n",
    "    \n",
    "    if stratified:\n",
    "        kf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=180820231)\n",
    "    else:\n",
    "        kf = GroupKFold(n_splits=n_folds)\n",
    "        \n",
    "    print(f\"Training with {len(features)} features\")\n",
    "    \n",
    "    if how == 'linreg' or how == 'logreg':\n",
    "        scaler = StandardScaler()\n",
    "        X[X.columns] = scaler.fit_transform(X)\n",
    "    \n",
    "    for fold, (fit_idx, val_idx) in enumerate(kf.split(X, y, groups)):\n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        if how == 'lgbmc':\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                      eval_metric='multiclass', verbose=100)\n",
    "            # best_iter = model.best_iteration_\n",
    "        elif how == 'logreg':\n",
    "            model = LogisticRegression(C=0.1, max_iter=100000)#, class_weight='balanced')\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        oof[val_idx, :] = val_preds\n",
    "        val_score = log_loss(y_val, val_preds)\n",
    "        print(val_score)\n",
    "\n",
    "    return oof\n",
    "\n",
    "oof = model_train(train_df, how='lgbmc', n_folds=5, stratified=True) # 77.78546798415482\n",
    "\n",
    "y = np.clip(np.round((train_df['target'] - train_df['close']) / train_df['close'] * 100, 0), -2, 2) + 2\n",
    "log_loss(y, oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4339585802642052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_df[train_cols]\u001b[39m.\u001b[39mloc[:,lr\u001b[39m.\u001b[39mcoef_ \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_cols' is not defined"
     ]
    }
   ],
   "source": [
    "train_df[train_cols].loc[:,lr.coef_ > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.618049225159526"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X, y = train_df[train_cols], (train_df['target'] > train_df['open']).map({True: 1, False: 0})\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logr = LogisticRegression(C=0.1, max_iter=100000, class_weight='balanced')\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "preds = logr.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715587967183227"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = train_df[train_cols], (train_df['target'] > train_df['open']).map({True: 1, False: 0})\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lgbc = lgb.LGBMClassifier()\n",
    "lgbc.fit(X_train, y_train)\n",
    "\n",
    "preds = lgbc.predict(X_val)\n",
    "accuracy_score(y_val, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
