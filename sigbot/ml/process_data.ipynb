{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from os import environ\n",
    "import pandas as pd\n",
    "from indicators import indicators\n",
    "from datetime import timedelta\n",
    "from tqdm.auto import tqdm\n",
    "from config.config import ConfigFactory\n",
    "\n",
    "class CFG:\n",
    "    cls_target_ratio = 1.021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and add indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84d3176a23942459741a129340b204c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 159>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39msignal_stat/buy_stat_1h.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m \u001b[39m# dataset for model train\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m train_buy \u001b[39m=\u001b[39m create_train_df(df, \u001b[39m'\u001b[39;49m\u001b[39mbuy\u001b[39;49m\u001b[39m'\u001b[39;49m, configs, target_offset, first, last, step)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m train_buy \u001b[39m=\u001b[39m train_buy\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m \u001b[39m# Sell\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39m# dataset with the signal statistics\u001b[39;00m\n",
      "\u001b[1;32m/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb Cell 4\u001b[0m in \u001b[0;36mcreate_train_df\u001b[0;34m(df, ttype, configs, target_offset, first, last, step)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     tmp_df_1h_buy \u001b[39m=\u001b[39m add_indicators(tmp_df_1h, \u001b[39m'\u001b[39m\u001b[39mbuy\u001b[39m\u001b[39m'\u001b[39m, configs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     tmp_df_1h_sell \u001b[39m=\u001b[39m add_indicators(tmp_df_1h, \u001b[39m'\u001b[39m\u001b[39msell\u001b[39m\u001b[39m'\u001b[39m, configs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     tmp_df_1h \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([tmp_df_1h_buy, tmp_df_1h_sell])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;32m/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb Cell 4\u001b[0m in \u001b[0;36mcreate_train_df\u001b[0;34m(df, ttype, configs, target_offset, first, last, step)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     tmp_df_1h_buy \u001b[39m=\u001b[39m add_indicators(tmp_df_1h, \u001b[39m'\u001b[39m\u001b[39mbuy\u001b[39m\u001b[39m'\u001b[39m, configs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     tmp_df_1h_sell \u001b[39m=\u001b[39m add_indicators(tmp_df_1h, \u001b[39m'\u001b[39m\u001b[39msell\u001b[39m\u001b[39m'\u001b[39m, configs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     tmp_df_1h \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([tmp_df_1h_buy, tmp_df_1h_sell])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alex/Trading/sigbot/sigbot/ml/process_data.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set environment variable\n",
    "environ[\"ENV\"] = \"1h_4h\"\n",
    "\n",
    "# Get configs\n",
    "configs = ConfigFactory.factory(environ).configs\n",
    "\n",
    "def get_file(ticker):\n",
    "    ''' Find files buy ticker names, file names can be in different formats '''\n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def add_indicators(df, ttype, configs):\n",
    "    # add RSI\n",
    "    rsi = indicators.RSI(ttype, configs)\n",
    "    df = rsi.get_indicator(df, '', '', 0)\n",
    "    # add RSI\n",
    "    stoch = indicators.STOCH(ttype, configs)\n",
    "    df = stoch.get_indicator(df, '', '', 0)\n",
    "    # add Trend\n",
    "    trend = indicators.Trend(ttype, configs)\n",
    "    df = trend.get_indicator(df, '', '', 0)\n",
    "    # add MACD\n",
    "    macd = indicators.MACD(ttype, configs)\n",
    "    df = macd.get_indicator(df, '', '', 0)\n",
    "    # add ATR\n",
    "    atr = indicators.ATR(ttype, configs)\n",
    "    df = atr.get_indicator(df, '', '', 0)\n",
    "    # add SMA\n",
    "    # sma = indicators.SMA(ttype, configs)\n",
    "    # df = sma.get_indicator(df, '', '', 0)\n",
    "    return df\n",
    "\n",
    "def create_train_df(df, ttype, configs, target_offset, first, last, step):\n",
    "    ''' Create train dataset from signal statistics and ticker candle data'''\n",
    "    train_df = pd.DataFrame()\n",
    "    tickers = df['ticker'].unique()\n",
    "    \n",
    "    for ticker in tqdm(tickers):\n",
    "        # get signals with current ticker\n",
    "        signal_df = df[df['ticker'] == ticker]\n",
    "        times = signal_df['time']\n",
    "        \n",
    "        # load candle history of this ticker\n",
    "        tmp_df_1h, _ = get_file(ticker)\n",
    "\n",
    "        # add indicators \n",
    "        try:\n",
    "            tmp_df_1h = add_indicators(tmp_df_1h, ttype, configs)\n",
    "        except TypeError:\n",
    "            continue\n",
    "\n",
    "        # add historical data for current ticker\n",
    "        for i, t in enumerate(times.to_list()):\n",
    "            pass_cycle = False\n",
    "            pattern = signal_df.iloc[i, signal_df.columns.get_loc('pattern')]\n",
    "            row = tmp_df_1h.loc[tmp_df_1h['time'] == t, :].reset_index(drop=True)\n",
    "            \n",
    "            for i in range(first, last + step, step):\n",
    "                time_prev = t + timedelta(hours= -i)\n",
    "                try:\n",
    "                    row_tmp = tmp_df_1h.loc[tmp_df_1h['time'] == time_prev, :].reset_index(drop=True)\n",
    "                    row_tmp.columns = [c + f'_prev_{i}' for c in row_tmp.columns]\n",
    "                except IndexError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                row = pd.concat([row, row_tmp.iloc[:,1:]], axis=1)\n",
    "                row['ticker'] = ticker\n",
    "                row['pattern'] = pattern\n",
    "                \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "\n",
    "            row['target'] = 0\n",
    "            \n",
    "            if row['pattern'].values == 'STOCH_RSI':\n",
    "                if ttype == 'buy':\n",
    "                    row['ttype'] = 'sell'\n",
    "                else:\n",
    "                    row['ttype'] = 'buy'\n",
    "            else:\n",
    "                row['ttype'] = ttype\n",
    "            \n",
    "            # If ttype = buy and during the selected period high price was higher than close_price * target_ratio\n",
    "            # and earlier low price wasn't lower than close_price / target_ratio, than target is True, else target is False.\n",
    "            # Similarly for ttype = sell \n",
    "            close_price = tmp_df_1h.loc[tmp_df_1h['time'] == t, 'close'].values\n",
    "            \n",
    "            for i in range(1, target_offset + 1):\n",
    "                time_next = t + timedelta(hours=i)\n",
    "                target_buy = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'high'].reset_index(drop=True)\n",
    "                target_sell = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'low'].reset_index(drop=True)\n",
    "\n",
    "                try:\n",
    "                    target_buy = target_buy > close_price * CFG.cls_target_ratio\n",
    "                    target_sell = target_sell < close_price / CFG.cls_target_ratio\n",
    "                except ValueError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    if (row['ttype'].values == 'buy' and target_sell[0]) or (row['ttype'].values == 'sell' and target_buy[0]):\n",
    "                        break\n",
    "                    elif (row['ttype'].values == 'buy' and target_buy[0]) or (row['ttype'].values == 'sell' and target_sell[0]):\n",
    "                        row['target'] = 1\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "            \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "\n",
    "            # add data to the dataset\n",
    "            if train_df.shape[0] == 0:\n",
    "                train_df = row\n",
    "            else:\n",
    "                train_df = pd.concat([train_df, row])\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# for how long time (in hours) we want to predict\n",
    "target_offset = 48\n",
    "# first previous data point to collect for model training (value represents number of hours before signal point)\n",
    "first = 4\n",
    "# last previous data point to collect for model training (value represents number of hours before signal point)\n",
    "last = 96\n",
    "# step of previous data points collecting (total number of points to collect is (last - first + step) / step)\n",
    "step = 4\n",
    "\n",
    "# Buy\n",
    "# dataset with the signal statistics\n",
    "df = pd.read_pickle('signal_stat/buy_stat_1h.pkl')\n",
    "# dataset for model train\n",
    "train_buy = create_train_df(df, 'buy', configs, target_offset, first, last, step)\n",
    "train_buy = train_buy.dropna()\n",
    "\n",
    "# Sell\n",
    "# dataset with the signal statistics\n",
    "df = pd.read_pickle('signal_stat/sell_stat_1h.pkl')\n",
    "# dataset for model train\n",
    "train_sell = create_train_df(df, 'sell', configs, target_offset, first, last, step)\n",
    "train_sell = train_sell.dropna()\n",
    "\n",
    "train_buy = pd.concat([train_buy, train_sell[train_sell['ttype'] == 'buy']]).sort_values('time').reset_index(drop=True)\n",
    "train_sell = pd.concat([train_sell, train_buy[train_buy['ttype'] == 'sell']]).sort_values('time').reset_index(drop=True)\n",
    "\n",
    "train_buy = train_buy[train_buy['ttype'] == 'buy']\n",
    "train_sell = train_sell[train_sell['ttype'] == 'sell']\n",
    "\n",
    "train_buy.to_pickle(f'signal_stat/train_buy_{last}.pkl')\n",
    "train_sell.to_pickle(f'signal_stat/train_sell_{last}.pkl')\n",
    "\n",
    "display(df.head())\n",
    "display(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttype\n",
       "buy    5624\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buy['ttype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttype\n",
       "sell    5956\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sell['ttype'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check pattern/target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  pattern      \n",
       "0       Pattern_Trend    1566\n",
       "1       Pattern_Trend    1485\n",
       "        MACD              913\n",
       "0       MACD              566\n",
       "        STOCH_RSI         564\n",
       "1       STOCH_RSI         530\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buy[['target', 'pattern']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  pattern      \n",
       "1       MACD             1852\n",
       "0       MACD             1157\n",
       "1       Pattern_Trend     927\n",
       "0       Pattern_Trend     919\n",
       "1       STOCH_RSI         587\n",
       "0       STOCH_RSI         514\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sell[['target', 'pattern']].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check target correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    2928\n",
       "0    2696\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buy['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    3366\n",
       "0    2590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sell['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 654\n",
    "\n",
    "# x = train_sell.loc[train_sell.target == 0, ['ticker', 'ttype', 'pattern', 'time', 'close', 'target']]\n",
    "# y = x.iloc[i]\n",
    "# low_price, high_price = y['close'] / CFG.cls_target_ratio, y['close'] * CFG.cls_target_ratio,\n",
    "# print(y['ticker'], y['time'], y['ttype'])\n",
    "\n",
    "# tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"]}_1h.pkl')\n",
    "# # tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"][:-4]}-{y[\"ticker\"][-4:]}_1h.pkl')\n",
    "# # tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"][:-4]}-{y[\"ticker\"][-4:]}-SWAP_4h.pkl')\n",
    "\n",
    "# tmp_df_1h['low_price'] = low_price\n",
    "# tmp_df_1h['high_price'] = high_price\n",
    "# idx = tmp_df_1h[tmp_df_1h['time'] == y['time']].index[0]\n",
    "\n",
    "# tmp_df_1h = tmp_df_1h.iloc[idx:idx+target_offset+1][['time', 'close', 'high', 'high_price', 'low', 'low_price']]\n",
    "\n",
    "# if y['ttype'] == 'buy':\n",
    "#     tmp_df_1h['signal'] = tmp_df_1h['high'] > tmp_df_1h['high_price']\n",
    "#     tmp_df_1h['anti_signal'] = tmp_df_1h['low'] < tmp_df_1h['low_price']\n",
    "# else:\n",
    "#     tmp_df_1h['signal'] = tmp_df_1h['low'] < tmp_df_1h['low_price']\n",
    "#     tmp_df_1h['anti_signal'] = tmp_df_1h['high'] > tmp_df_1h['high_price']\n",
    "\n",
    "# tmp_df_1h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
