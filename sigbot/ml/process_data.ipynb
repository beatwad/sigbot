{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=[FutureWarning, DeprecationWarning])\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from os import environ\n",
    "import pandas as pd\n",
    "from indicators import indicators\n",
    "from datetime import timedelta\n",
    "from tqdm.auto import tqdm\n",
    "from config.config import ConfigFactory\n",
    "\n",
    "class CFG:\n",
    "    cls_target_ratio = 1.031"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and add indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e452086c3324202ad89a51947607d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783fd973168f4848a185f547b70a991a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set environment variable\n",
    "environ[\"ENV\"] = \"1h_4h\"\n",
    "\n",
    "# Get configs\n",
    "configs = ConfigFactory.factory(environ).configs\n",
    "\n",
    "def get_file(ticker):\n",
    "    ''' Find files buy ticker names, file names can be in different formats '''\n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    try:\n",
    "        tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_1h.pkl')\n",
    "        tmp_df_4h = pd.read_pickle(f'../optimizer/ticker_dataframes/{ticker[:-4]}-{ticker[-4:]}-SWAP_4h.pkl')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        return tmp_df_1h, tmp_df_4h\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def add_indicators(df, ttype, configs):\n",
    "    # add RSI\n",
    "    rsi = indicators.RSI(ttype, configs)\n",
    "    df = rsi.get_indicator(df, '', '', 0)\n",
    "    # add RSI\n",
    "    stoch = indicators.STOCH(ttype, configs)\n",
    "    df = stoch.get_indicator(df, '', '', 0)\n",
    "    # add Trend\n",
    "    trend = indicators.Trend(ttype, configs)\n",
    "    df = trend.get_indicator(df, '', '', 0)\n",
    "    # add MACD\n",
    "    macd = indicators.MACD(ttype, configs)\n",
    "    df = macd.get_indicator(df, '', '', 0)\n",
    "    # add ATR\n",
    "    atr = indicators.ATR(ttype, configs)\n",
    "    df = atr.get_indicator(df, '', '', 0)\n",
    "    # add SMA\n",
    "    # sma = indicators.SMA(ttype, configs)\n",
    "    # df = sma.get_indicator(df, '', '', 0)\n",
    "    return df\n",
    "\n",
    "def create_train_df(df, ttype, configs, target_offset, first, last, step):\n",
    "    ''' Create train dataset from signal statistics and ticker candle data'''\n",
    "    train_df = pd.DataFrame()\n",
    "    tickers = df['ticker'].unique()\n",
    "    \n",
    "    for ticker in tqdm(tickers):\n",
    "        # get signals with current ticker\n",
    "        signal_df = df[df['ticker'] == ticker]\n",
    "        times = signal_df['time']\n",
    "        \n",
    "        # load candle history of this ticker\n",
    "        tmp_df_1h, _ = get_file(ticker)\n",
    "\n",
    "        # add indicators \n",
    "        try:\n",
    "            tmp_df_1h = add_indicators(tmp_df_1h, ttype, configs)\n",
    "        except TypeError:\n",
    "            continue\n",
    "\n",
    "        # add historical data for current ticker\n",
    "        for i, t in enumerate(times.to_list()):\n",
    "            pass_cycle = False\n",
    "            pattern = signal_df.iloc[i, signal_df.columns.get_loc('pattern')]\n",
    "            row = tmp_df_1h.loc[tmp_df_1h['time'] == t, :].reset_index(drop=True)\n",
    "            \n",
    "            for i in range(first, last + step, step):\n",
    "                time_prev = t + timedelta(hours= -i)\n",
    "                try:\n",
    "                    row_tmp = tmp_df_1h.loc[tmp_df_1h['time'] == time_prev, :].reset_index(drop=True)\n",
    "                    row_tmp.columns = [c + f'_prev_{i}' for c in row_tmp.columns]\n",
    "                except IndexError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                row = pd.concat([row, row_tmp.iloc[:,1:]], axis=1)\n",
    "                row['ticker'] = ticker\n",
    "                row['pattern'] = pattern\n",
    "                \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "\n",
    "            row['target'] = 0\n",
    "            row['ttype'] = ttype\n",
    "            \n",
    "            # If ttype = buy and during the selected period high price was higher than close_price * target_ratio\n",
    "            # and earlier low price wasn't lower than close_price / target_ratio, than target is True, else target is False.\n",
    "            # Similarly for ttype = sell \n",
    "            close_price = tmp_df_1h.loc[tmp_df_1h['time'] == t, 'close'].values\n",
    "            \n",
    "            for i in range(1, target_offset + 1):\n",
    "                time_next = t + timedelta(hours=i)\n",
    "                target_buy = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'high'].reset_index(drop=True)\n",
    "                target_sell = tmp_df_1h.loc[tmp_df_1h['time'] == time_next, 'low'].reset_index(drop=True)\n",
    "\n",
    "                try:\n",
    "                    target_buy = target_buy > close_price * CFG.cls_target_ratio\n",
    "                    target_sell = target_sell < close_price * (2 - CFG.cls_target_ratio)\n",
    "                except ValueError:\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    if (row['ttype'].values == 'buy' and target_sell[0]) or (row['ttype'].values == 'sell' and target_buy[0]):\n",
    "                        break\n",
    "                    elif (row['ttype'].values == 'buy' and target_buy[0]) or (row['ttype'].values == 'sell' and target_sell[0]):\n",
    "                        row['target'] = 1\n",
    "                        break\n",
    "                except (KeyError, TypeError):\n",
    "                    pass_cycle = True\n",
    "                    break\n",
    "            \n",
    "            if pass_cycle:\n",
    "                continue\n",
    "\n",
    "            # add data to the dataset\n",
    "            if train_df.shape[0] == 0:\n",
    "                train_df = row\n",
    "            else:\n",
    "                train_df = pd.concat([train_df, row])\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# for how long time (in hours) we want to predict\n",
    "target_offset = 96\n",
    "# first previous data point to collect for model training (value represents number of hours before signal point)\n",
    "first = 4\n",
    "# last previous data point to collect for model training (value represents number of hours before signal point)\n",
    "last = 192\n",
    "# step of previous data points collecting (total number of points to collect is (last - first + step) / step)\n",
    "step = 4\n",
    "\n",
    "# Buy\n",
    "# dataset with the signal statistics\n",
    "df = pd.read_pickle('signal_stat/buy_stat_1h.pkl')\n",
    "# dataset for model train\n",
    "train_buy = create_train_df(df, 'buy', configs, target_offset, first, last, step)\n",
    "train_buy = train_buy.dropna()\n",
    "\n",
    "# Sell\n",
    "# dataset with the signal statistics\n",
    "df = pd.read_pickle('signal_stat/sell_stat_1h.pkl')\n",
    "# dataset for model train\n",
    "train_sell = create_train_df(df, 'sell', configs, target_offset, first, last, step)\n",
    "train_sell = train_sell.dropna()\n",
    "\n",
    "train_buy = pd.concat([train_buy, train_sell[train_sell['ttype'] == 'buy']]).sort_values('time').reset_index(drop=True)\n",
    "train_sell = pd.concat([train_sell, train_buy[train_buy['ttype'] == 'sell']]).sort_values('time').reset_index(drop=True)\n",
    "\n",
    "train_buy = train_buy[train_buy['ttype'] == 'buy']\n",
    "train_sell = train_sell[train_sell['ttype'] == 'sell']\n",
    "\n",
    "train_buy.to_pickle(f'signal_stat/train_buy_{last}.pkl')\n",
    "train_sell.to_pickle(f'signal_stat/train_sell_{last}.pkl')\n",
    "\n",
    "# display(df.head())\n",
    "# display(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buy    1721\n",
       "Name: ttype, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buy['ttype'].value_counts() # 1607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sell    3391\n",
       "Name: ttype, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sell['ttype'].value_counts() # 3150"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check pattern/target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  pattern\n",
       "1       MACD       1096\n",
       "0       MACD        625\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buy[['target', 'pattern']].value_counts() # 1.031 -- 1019 / 588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  pattern\n",
       "1       MACD       1972\n",
       "0       MACD       1419\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sell[['target', 'pattern']].value_counts() # 1.031 -- 1815 / 1335"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check target correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 654\n",
    "\n",
    "# x = train_sell.loc[train_sell.target == 0, ['ticker', 'ttype', 'pattern', 'time', 'close', 'target']]\n",
    "# y = x.iloc[i]\n",
    "# low_price, high_price = y['close'] / CFG.cls_target_ratio, y['close'] * CFG.cls_target_ratio,\n",
    "# print(y['ticker'], y['time'], y['ttype'])\n",
    "\n",
    "# tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"]}_1h.pkl')\n",
    "# # tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"][:-4]}-{y[\"ticker\"][-4:]}_1h.pkl')\n",
    "# # tmp_df_1h = pd.read_pickle(f'../optimizer/ticker_dataframes/{y[\"ticker\"][:-4]}-{y[\"ticker\"][-4:]}-SWAP_4h.pkl')\n",
    "\n",
    "# tmp_df_1h['low_price'] = low_price\n",
    "# tmp_df_1h['high_price'] = high_price\n",
    "# idx = tmp_df_1h[tmp_df_1h['time'] == y['time']].index[0]\n",
    "\n",
    "# tmp_df_1h = tmp_df_1h.iloc[idx:idx+target_offset+1][['time', 'close', 'high', 'high_price', 'low', 'low_price']]\n",
    "\n",
    "# if y['ttype'] == 'buy':\n",
    "#     tmp_df_1h['signal'] = tmp_df_1h['high'] > tmp_df_1h['high_price']\n",
    "#     tmp_df_1h['anti_signal'] = tmp_df_1h['low'] < tmp_df_1h['low_price']\n",
    "# else:\n",
    "#     tmp_df_1h['signal'] = tmp_df_1h['low'] < tmp_df_1h['low_price']\n",
    "#     tmp_df_1h['anti_signal'] = tmp_df_1h['high'] > tmp_df_1h['high_price']\n",
    "\n",
    "# tmp_df_1h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
