{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from shaphypetune import BoostBoruta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import log_loss, mean_squared_error, precision_score\n",
    "\n",
    "import torch\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    ttype = 'buy'\n",
    "    select_features = False\n",
    "    train_NN = False\n",
    "    train_LGBM = True\n",
    "    n_repeats = 1\n",
    "    n_folds = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and add indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stoch_slowk</th>\n",
       "      <th>stoch_slowd</th>\n",
       "      <th>stoch_slowk_dir</th>\n",
       "      <th>...</th>\n",
       "      <th>linear_reg_angle_prev_96</th>\n",
       "      <th>macd_prev_96</th>\n",
       "      <th>macdsignal_prev_96</th>\n",
       "      <th>macdhist_prev_96</th>\n",
       "      <th>macd_dir_prev_96</th>\n",
       "      <th>macdsignal_dir_prev_96</th>\n",
       "      <th>atr_prev_96</th>\n",
       "      <th>close_smooth_prev_96</th>\n",
       "      <th>target</th>\n",
       "      <th>ttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-27 07:00:00</td>\n",
       "      <td>0.32290</td>\n",
       "      <td>0.32410</td>\n",
       "      <td>0.32270</td>\n",
       "      <td>0.32320</td>\n",
       "      <td>235279.000</td>\n",
       "      <td>34.957293</td>\n",
       "      <td>35.958102</td>\n",
       "      <td>36.687176</td>\n",
       "      <td>-0.013187</td>\n",
       "      <td>...</td>\n",
       "      <td>5.007458</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.396215</td>\n",
       "      <td>1.688159</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>1</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-27 11:00:00</td>\n",
       "      <td>116.10000</td>\n",
       "      <td>116.70000</td>\n",
       "      <td>115.30000</td>\n",
       "      <td>115.50000</td>\n",
       "      <td>3039.310</td>\n",
       "      <td>74.723751</td>\n",
       "      <td>81.513130</td>\n",
       "      <td>83.198644</td>\n",
       "      <td>-0.014239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832463</td>\n",
       "      <td>0.377508</td>\n",
       "      <td>0.098834</td>\n",
       "      <td>0.278674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.866341</td>\n",
       "      <td>0.978604</td>\n",
       "      <td>104.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-27 11:00:00</td>\n",
       "      <td>0.00809</td>\n",
       "      <td>0.00811</td>\n",
       "      <td>0.00807</td>\n",
       "      <td>0.00809</td>\n",
       "      <td>1430983.000</td>\n",
       "      <td>37.197893</td>\n",
       "      <td>12.453618</td>\n",
       "      <td>15.696450</td>\n",
       "      <td>-0.215170</td>\n",
       "      <td>...</td>\n",
       "      <td>4.860881</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.306505</td>\n",
       "      <td>-0.232215</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27 15:00:00</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.12960</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>127742.400</td>\n",
       "      <td>45.719042</td>\n",
       "      <td>34.799877</td>\n",
       "      <td>45.173802</td>\n",
       "      <td>-0.153118</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.273112</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-0.198655</td>\n",
       "      <td>-0.119878</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.134296</td>\n",
       "      <td>1</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-27 15:00:00</td>\n",
       "      <td>3.59900</td>\n",
       "      <td>3.60700</td>\n",
       "      <td>3.56900</td>\n",
       "      <td>3.57000</td>\n",
       "      <td>39715.799</td>\n",
       "      <td>43.030553</td>\n",
       "      <td>32.630507</td>\n",
       "      <td>36.945566</td>\n",
       "      <td>-0.096957</td>\n",
       "      <td>...</td>\n",
       "      <td>9.413859</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.024708</td>\n",
       "      <td>3.548208</td>\n",
       "      <td>1</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time       open       high        low      close  \\\n",
       "0 2022-12-27 07:00:00    0.32290    0.32410    0.32270    0.32320   \n",
       "1 2022-12-27 11:00:00  116.10000  116.70000  115.30000  115.50000   \n",
       "2 2022-12-27 11:00:00    0.00809    0.00811    0.00807    0.00809   \n",
       "3 2022-12-27 15:00:00    0.12940    0.12960    0.12890    0.12890   \n",
       "4 2022-12-27 15:00:00    3.59900    3.60700    3.56900    3.57000   \n",
       "\n",
       "        volume        rsi  stoch_slowk  stoch_slowd  stoch_slowk_dir  ...  \\\n",
       "0   235279.000  34.957293    35.958102    36.687176        -0.013187  ...   \n",
       "1     3039.310  74.723751    81.513130    83.198644        -0.014239  ...   \n",
       "2  1430983.000  37.197893    12.453618    15.696450        -0.215170  ...   \n",
       "3   127742.400  45.719042    34.799877    45.173802        -0.153118  ...   \n",
       "4    39715.799  43.030553    32.630507    36.945566        -0.096957  ...   \n",
       "\n",
       "   linear_reg_angle_prev_96  macd_prev_96  macdsignal_prev_96  \\\n",
       "0                  5.007458      0.001522            0.000284   \n",
       "1                  0.832463      0.377508            0.098834   \n",
       "2                  4.860881      0.000006           -0.000008   \n",
       "3                -11.273112     -0.000115           -0.000398   \n",
       "4                  9.413859      0.011712            0.010892   \n",
       "\n",
       "   macdhist_prev_96  macd_dir_prev_96  macdsignal_dir_prev_96  atr_prev_96  \\\n",
       "0          0.001238          0.396215                1.688159     0.002535   \n",
       "1          0.278674          0.000000               -0.866341     0.978604   \n",
       "2          0.000014          0.306505               -0.232215     0.000068   \n",
       "3          0.000283         -0.198655               -0.119878     0.000941   \n",
       "4          0.000821          0.000000                0.015875     0.024708   \n",
       "\n",
       "   close_smooth_prev_96  target  ttype  \n",
       "0              0.307438       1   sell  \n",
       "1            104.266667       0    buy  \n",
       "2              0.007726       0   sell  \n",
       "3              0.134296       1   sell  \n",
       "4              3.548208       1   sell  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7050, 505)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stoch_slowk</th>\n",
       "      <th>stoch_slowd</th>\n",
       "      <th>stoch_slowk_dir</th>\n",
       "      <th>...</th>\n",
       "      <th>linear_reg_angle_prev_96</th>\n",
       "      <th>macd_prev_96</th>\n",
       "      <th>macdsignal_prev_96</th>\n",
       "      <th>macdhist_prev_96</th>\n",
       "      <th>macd_dir_prev_96</th>\n",
       "      <th>macdsignal_dir_prev_96</th>\n",
       "      <th>atr_prev_96</th>\n",
       "      <th>close_smooth_prev_96</th>\n",
       "      <th>target</th>\n",
       "      <th>ttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-26 01:00:00</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>23.7600</td>\n",
       "      <td>23.8400</td>\n",
       "      <td>13772.65</td>\n",
       "      <td>64.054892</td>\n",
       "      <td>83.517327</td>\n",
       "      <td>87.090858</td>\n",
       "      <td>-0.029809</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.369665</td>\n",
       "      <td>-0.020052</td>\n",
       "      <td>-0.052992</td>\n",
       "      <td>0.032940</td>\n",
       "      <td>-0.201703</td>\n",
       "      <td>-0.103966</td>\n",
       "      <td>0.133742</td>\n",
       "      <td>22.383333</td>\n",
       "      <td>1</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-26 05:00:00</td>\n",
       "      <td>24.0400</td>\n",
       "      <td>24.1000</td>\n",
       "      <td>23.9800</td>\n",
       "      <td>24.0300</td>\n",
       "      <td>8515.96</td>\n",
       "      <td>68.293118</td>\n",
       "      <td>54.118435</td>\n",
       "      <td>61.220840</td>\n",
       "      <td>-0.108235</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.869113</td>\n",
       "      <td>-0.017024</td>\n",
       "      <td>-0.033512</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>0.121932</td>\n",
       "      <td>22.381250</td>\n",
       "      <td>1</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-06 11:00:00</td>\n",
       "      <td>23.1300</td>\n",
       "      <td>23.6400</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>23.4700</td>\n",
       "      <td>195485.06</td>\n",
       "      <td>33.589815</td>\n",
       "      <td>17.450236</td>\n",
       "      <td>12.459531</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.240717</td>\n",
       "      <td>-0.018542</td>\n",
       "      <td>-0.006710</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075655</td>\n",
       "      <td>0.200640</td>\n",
       "      <td>25.909167</td>\n",
       "      <td>1</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-08 06:00:00</td>\n",
       "      <td>19.2700</td>\n",
       "      <td>19.5500</td>\n",
       "      <td>17.0400</td>\n",
       "      <td>17.9400</td>\n",
       "      <td>2324262.07</td>\n",
       "      <td>16.426697</td>\n",
       "      <td>21.681996</td>\n",
       "      <td>20.663002</td>\n",
       "      <td>0.096723</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.781879</td>\n",
       "      <td>-0.209272</td>\n",
       "      <td>-0.227469</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016908</td>\n",
       "      <td>0.208816</td>\n",
       "      <td>24.600833</td>\n",
       "      <td>0</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-27 09:00:00</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>0.3688</td>\n",
       "      <td>19678900.00</td>\n",
       "      <td>69.684900</td>\n",
       "      <td>34.733219</td>\n",
       "      <td>35.353221</td>\n",
       "      <td>-0.096031</td>\n",
       "      <td>...</td>\n",
       "      <td>7.045257</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159713</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.346717</td>\n",
       "      <td>0</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time     open     high      low    close       volume  \\\n",
       "0 2022-10-26 01:00:00  24.1500  24.1500  23.7600  23.8400     13772.65   \n",
       "1 2022-10-26 05:00:00  24.0400  24.1000  23.9800  24.0300      8515.96   \n",
       "2 2022-11-06 11:00:00  23.1300  23.6400  22.8200  23.4700    195485.06   \n",
       "3 2022-11-08 06:00:00  19.2700  19.5500  17.0400  17.9400   2324262.07   \n",
       "4 2022-12-27 09:00:00   0.3615   0.3691   0.3614   0.3688  19678900.00   \n",
       "\n",
       "         rsi  stoch_slowk  stoch_slowd  stoch_slowk_dir  ...  \\\n",
       "0  64.054892    83.517327    87.090858        -0.029809  ...   \n",
       "1  68.293118    54.118435    61.220840        -0.108235  ...   \n",
       "2  33.589815    17.450236    12.459531         0.221789  ...   \n",
       "3  16.426697    21.681996    20.663002         0.096723  ...   \n",
       "4  69.684900    34.733219    35.353221        -0.096031  ...   \n",
       "\n",
       "   linear_reg_angle_prev_96  macd_prev_96  macdsignal_prev_96  \\\n",
       "0                -10.369665     -0.020052           -0.052992   \n",
       "1                -11.869113     -0.017024           -0.033512   \n",
       "2                 -4.240717     -0.018542           -0.006710   \n",
       "3                -10.781879     -0.209272           -0.227469   \n",
       "4                  7.045257      0.001233            0.000785   \n",
       "\n",
       "   macdhist_prev_96  macd_dir_prev_96  macdsignal_dir_prev_96  atr_prev_96  \\\n",
       "0          0.032940         -0.201703               -0.103966     0.133742   \n",
       "1          0.016488          0.000000               -0.106127     0.121932   \n",
       "2         -0.011832          0.000000                0.075655     0.200640   \n",
       "3          0.018198          0.000000               -0.016908     0.208816   \n",
       "4          0.000447          0.000000                0.159713     0.002303   \n",
       "\n",
       "   close_smooth_prev_96  target  ttype  \n",
       "0             22.383333       1    buy  \n",
       "1             22.381250       1    buy  \n",
       "2             25.909167       1   sell  \n",
       "3             24.600833       0   sell  \n",
       "4              0.346717       0    buy  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7257, 505)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11601, 385)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# last previous data point to collect for model training (value represents number of hours before signal point)\n",
    "last = 96\n",
    "\n",
    "if CFG.ttype == 'buy':\n",
    "    df = pd.read_pickle(f'signal_stat/train_buy_{last}.pkl')\n",
    "else:\n",
    "    df = pd.read_pickle(f'signal_stat/train_sell_{last}.pkl')\n",
    "\n",
    "# df = df[df['pattern'].isin(['MACD', 'STOCH_RSI'])]\n",
    "\n",
    "display(df.head())\n",
    "display(df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split by ticker group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=0.1, n_splits=2, random_state = 7)\n",
    "\n",
    "split = splitter.split(df, groups=df['ticker'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train_df = df.iloc[train_inds]\n",
    "test_df = df.iloc[test_inds]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_size=0.2\n",
    "\n",
    "x_data = train_df.drop(['target', 'time', 'ticker', 'pattern', 'ttype'], axis=1)\n",
    "y_data = train_df['target']\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, test_size=test_size, shuffle=True)\n",
    "input_channels = x_data.shape[1]\n",
    "output_size = len(set(y_data))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train[x_train.columns] = scaler.fit_transform(x_train)\n",
    "x_valid[x_valid.columns] = scaler.transform(x_valid)\n",
    "\n",
    "x_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "x_valid = torch.tensor(x_valid.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.float32)\n",
    "\n",
    "display(type(x_train), type(y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find available device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find available device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigModel(torch.nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(SigModel, self, ).__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.layers.add_module('lin1', torch.nn.Linear(input_channels, 64))\n",
    "        self.layers.add_module('relu1', torch.nn.ReLU())\n",
    "        self.layers.add_module('do1', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin2', torch.nn.Linear(64, 128))\n",
    "        self.layers.add_module('relu2', torch.nn.ReLU())\n",
    "        self.layers.add_module('do2', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin3', torch.nn.Linear(128, 96))\n",
    "        self.layers.add_module('relu3', torch.nn.ReLU())\n",
    "        self.layers.add_module('do3', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin4', torch.nn.Linear(96, 32))\n",
    "        self.layers.add_module('relu4', torch.nn.ReLU())\n",
    "        self.layers.add_module('do4', torch.nn.Dropout(p=0.25))\n",
    "        self.layers.add_module('lin5', torch.nn.Linear(32, 1))\n",
    "        self.layers.add_module('sigmoid', torch.nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "# train function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler):\n",
    "    # put the model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_loader\n",
    "\n",
    "    # get output of the model\n",
    "    train_preds = model(x_train).squeeze()\n",
    "    # calculate train loss\n",
    "    train_loss = criterion(train_preds, y_train)\n",
    "    train_acc = (train_preds.round() == y_train).float().mean()\n",
    "    \n",
    "    # set gradient to zero to prevent it accumulation\n",
    "    optimizer.zero_grad() # ~ model.zero_grad()\n",
    "    # calculate gradient\n",
    "    train_loss.backward() \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(x_valid).squeeze()\n",
    "        val_loss = criterion(val_preds, y_valid)\n",
    "        val_acc = (val_preds.round() == y_valid).float().mean()\n",
    "    \n",
    "    # update weights according to gradient value\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "# Initialize model\n",
    "if CFG.train_NN:\n",
    "    model = SigModel(input_channels).to(device)\n",
    "\n",
    "    # Number of epochs\n",
    "    epochs = 100000\n",
    "\n",
    "    # Send data to the device\n",
    "    x_train, x_valid = x_train.to(device), x_valid.to(device)\n",
    "    y_train, y_valid = y_train.to(device), y_valid.to(device)\n",
    "    train_loader = x_train, x_valid, y_train, y_valid\n",
    "\n",
    "    # Empty loss lists to track values\n",
    "    epoch_count, train_loss_values, valid_loss_values = [], [], []\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    learning_rate = 1e-6\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2000, threshold=1e-2)\n",
    "\n",
    "    # Loop through the data\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc, val_loss, val_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler)\n",
    "\n",
    "        # Print progress a total of 20 times\n",
    "        if epoch % int(epochs / 20) == 0:\n",
    "            print(f'Epoch: {epoch:4.0f} | Train Loss: {train_loss:.5f}, Train Acc: {train_acc:.5f}\\\n",
    "                Validation Loss: {val_loss:.5f}, Val Acc: {val_acc:.5f}\\\n",
    "                    LR: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]}')\n",
    "\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(train_loss.cpu().detach().numpy())\n",
    "            valid_loss_values.append(val_loss.cpu().detach().numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot NN train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if CFG.train_NN:\n",
    "    plt.plot(epoch_count, train_loss_values, label='Training Loss')\n",
    "    plt.plot(epoch_count, valid_loss_values, label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss Curves')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "def lgbm_tuning(df, permut=False, boruta=False):\n",
    "    features = [c for c in df.columns if c not in ['time', 'target', 'ticker', 'pattern', 'ttype']]\n",
    "    groups = df['ticker']\n",
    "\n",
    "    outer_cv_score = [] # store all cv scores of outer loop inference\n",
    "\n",
    "    perm_df_ = pd.DataFrame()\n",
    "    feature_importances_ = pd.DataFrame()\n",
    "    boruta_df_ = pd.DataFrame()\n",
    "    \n",
    "    for i in range(CFG.n_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "        \n",
    "        if task_type == 'cls':\n",
    "            y_fold = df['target']\n",
    "            kf = StratifiedGroupKFold(n_splits=CFG.n_folds, shuffle=True, random_state=180820231)\n",
    "            eval_metric = 'logloss'\n",
    "        else:\n",
    "            y_fold = (df['target'] - df['close']) / df['close']\n",
    "            kf = GroupKFold(n_splits=CFG.n_folds)\n",
    "            eval_metric = 'mse'\n",
    "\n",
    "        X, y = df[features], y_fold\n",
    "        oof = np.zeros(len(df))\n",
    "        models_ = [] # Used to store models trained in the inner loop.\n",
    "        \n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y, groups)):\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            if task_type == 'cls':\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "            else:\n",
    "                clf = lgb.LGBMRegressor(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                    eval_metric=eval_metric, \n",
    "                    callbacks=[lgb.log_evaluation(100)])\n",
    "\n",
    "            models_.append(clf)\n",
    "\n",
    "            if task_type == 'cls':\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                val_score = log_loss(y_val, val_preds)\n",
    "            else:\n",
    "                val_preds = clf.predict(X_val)\n",
    "                val_score = mean_squared_error(y_val, val_preds, squared=False)\n",
    "            \n",
    "            oof[val_idx] = val_preds\n",
    "            best_iter = clf.best_iteration_\n",
    "\n",
    "            print(f'Fold: {blu}{fold + 1:>3}{res}| loss: {blu}{val_score:.5f}{res}| Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "            # permutation importance\n",
    "            if permut:\n",
    "                perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                             random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                    index=X_val.columns).sort_index()\n",
    "\n",
    "                if perm_df_.shape[0] == 0:\n",
    "                    perm_df_ = perm_importance_df.copy()\n",
    "                else:\n",
    "                    perm_df_ += perm_importance_df\n",
    "\n",
    "            # gboost feature importance\n",
    "            f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                      reverse=True, key=lambda x: x[1]), \n",
    "                                columns=['Value','Feature'])\n",
    "\n",
    "            if feature_importances_.shape[0] == 0:\n",
    "                feature_importances_ = f_i.copy()\n",
    "            else:\n",
    "                feature_importances_['Value'] += f_i['Value']\n",
    "                    \n",
    "            # BORUTA importance\n",
    "            if boruta:\n",
    "                model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                try:\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                            eval_metric=eval_metric, \n",
    "                            callbacks=[lgb.log_evaluation(100)])\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "                \n",
    "                boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                        index=X_train.columns).sort_index()\n",
    "                if boruta_df_.shape[0] == 0:\n",
    "                    boruta_df_ = boruta_importance_df.copy()\n",
    "                else:\n",
    "                    boruta_df_ += boruta_importance_df\n",
    "\n",
    "        if task_type == 'cls':\n",
    "            outer_cv = log_loss(y, oof)\n",
    "        else:\n",
    "            outer_cv = mean_squared_error(y, oof, squared=False)\n",
    "        \n",
    "        outer_cv_score.append(outer_cv)\n",
    "\n",
    "    print(f'{red} Outer Holdout avg score: {res} log_loss: {red}{np.mean(outer_cv_score):.5f}{res}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    \n",
    "    if permut:\n",
    "        perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "        perm_df_ = perm_df_.reset_index().rename({'index': 'Feature'}, axis=1)\n",
    "        \n",
    "    if boruta and boruta_df_.shape[0] > 0:\n",
    "        boruta_df_ = boruta_df_.sort_values('importance')\n",
    "        boruta_df_ = boruta_df_.reset_index().rename({'index': 'Feature'}, axis=1)\n",
    "                                    \n",
    "    feature_importances_ = feature_importances_.sort_values('Value', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return perm_df_, feature_importances_, boruta_df_, np.mean(outer_cv_score)\n",
    "\n",
    "\n",
    "params = {\n",
    "          'n_estimators': 2000,\n",
    "          'learning_rate': 0.02,\n",
    "        #   'early_stopping_round': 100,\n",
    "          'max_depth': 10,\n",
    "          'subsample' : 0.7,\n",
    "          'colsample_bytree': 0.85,\n",
    "          'num_leaves': 24,\n",
    "          'verbosity': -1,\n",
    "          'importance_type': 'gain',\n",
    "          'max_bin': 255,\n",
    "          'reg_alpha': 1e-6,\n",
    "          'reg_lambda': 1e-8\n",
    "        }\n",
    "\n",
    "task_type = 'cls'\n",
    "\n",
    "if task_type == 'cls':\n",
    "    params['boosting_type'] = 'dart'\n",
    "    params['objective'] = 'binary'\n",
    "else:\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'regression'\n",
    "\n",
    "if CFG.select_features:\n",
    "    perm_df_, feature_importances_, boruta_df_, outer_cv_score = lgbm_tuning(df, permut=True, boruta=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine importances and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features:\n",
    "    perm_df_['rank'] = perm_df_['importance'].rank(ascending=False)\n",
    "    boruta_df_['rank'] = boruta_df_['importance'].rank()\n",
    "    feature_importances_['rank'] = feature_importances_['Value'].rank(ascending=False)\n",
    "\n",
    "    fi = pd.concat([perm_df_[['Feature','rank']], feature_importances_[['Feature','rank']], boruta_df_[['Feature','rank']]])\n",
    "    fi = fi.groupby('Feature')['rank'].sum().sort_values().reset_index()\n",
    "    fi.to_csv(f'feature_importance_{CFG.ttype}.csv')\n",
    "else:\n",
    "    fi = pd.read_csv(f'feature_importance_all.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test split based on ticker groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_Pattern_Trend</th>\n",
       "      <th>pattern_STOCH_RSI</th>\n",
       "      <th>ttype_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11597</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11598</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11599</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11600</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pattern_Pattern_Trend  pattern_STOCH_RSI  ttype_sell\n",
       "0                       True              False       False\n",
       "1                      False              False       False\n",
       "2                      False              False       False\n",
       "3                      False              False        True\n",
       "4                      False              False        True\n",
       "...                      ...                ...         ...\n",
       "11596                  False              False       False\n",
       "11597                   True              False       False\n",
       "11598                  False               True       False\n",
       "11599                  False               True       False\n",
       "11600                   True              False       False\n",
       "\n",
       "[10400 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train_df[['pattern', 'ttype']], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(df, train_df, test_df, features, task_type, how, n_folds, low_bound, high_bound, train_test): \n",
    "    X, groups = train_df[features], train_df['ticker']\n",
    "    X = pd.concat([X, pd.get_dummies(train_df[['pattern', 'ttype']], drop_first=True)], axis=1)\n",
    "    y = train_df['target']\n",
    "    \n",
    "    if train_test == 'fold':\n",
    "        oof = np.zeros([train_df['target'].shape[0], 1])\n",
    "        \n",
    "        kf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=180820231)\n",
    "\n",
    "        oe_enc = OrdinalEncoder()\n",
    "        groups = oe_enc.fit_transform(groups.values.reshape(-1, 1))\n",
    "\n",
    "        print(f\"Training with {len(features)} features\")\n",
    "        \n",
    "        if how == 'lreg':\n",
    "            scaler = StandardScaler()\n",
    "            X[X.columns] = scaler.fit_transform(X)\n",
    "        \n",
    "        for fold, (fit_idx, val_idx) in enumerate(kf.split(X, y, groups)):\n",
    "            print(f'Fold #{fold + 1}')\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[fit_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[fit_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "            \n",
    "            models = list()\n",
    "            if how == 'lgbm':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                        eval_metric='logloss', callbacks = [lgb.log_evaluation(100)])\n",
    "            elif how == 'lreg':\n",
    "                model = LogisticRegression(C=0.1, max_iter=100000)#, class_weight='balanced')\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "            val_preds = model.predict_proba(X_val)\n",
    "            val_score = log_loss(y_val, val_preds)\n",
    "            prec_score, prec_obj_pct = confident_score(y_val, val_preds[:,1], low_bound, high_bound)\n",
    "            print(f'Logloss: {val_score}, Confident objects precision: {prec_score}, % of confident objects: {prec_obj_pct}')\n",
    "            oof[val_idx, 0] = val_preds[:,1]\n",
    "\n",
    "        return oof, model\n",
    "    elif train_test == 'full':\n",
    "        print('Train on full data')\n",
    "        X, y = df[features], df['target']\n",
    "        X = pd.concat([X, pd.get_dummies(df[['pattern', 'ttype']], drop_first=True)], axis=1)\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X, y, eval_set=[(X, y)], eval_metric='logloss', callbacks = [lgb.log_evaluation(100)])\n",
    "        return np.zeros([df.shape[0], 1]), model\n",
    "    else:\n",
    "        # fit model on full dataset and predict on test\n",
    "        print(\"Test fold\")\n",
    "        X_test, y_test = test_df[features], test_df['target']\n",
    "        X_test = pd.concat([X_test, pd.get_dummies(test_df[['pattern', 'ttype']], drop_first=True)], axis=1)\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X, y, eval_set=[(X_test, y_test)], eval_metric='logloss', callbacks = [lgb.log_evaluation(100)])\n",
    "        oof_test = np.zeros([test_df['target'].shape[0], 1])\n",
    "        oof_test[:,0] = model.predict_proba(X_test)[:,1]\n",
    "        return oof_test, model\n",
    "\n",
    "def prepare_features(fi, feature_num):\n",
    "    ''' Get features, sort them by their time appearance and return for using in train and inference'''\n",
    "    fi = fi['Feature'].head(feature_num)\n",
    "    feature_dict = defaultdict(list)\n",
    "    features = list()\n",
    "\n",
    "    for f in fi:\n",
    "        period = f.split('_')\n",
    "        if period[-1].isdigit():\n",
    "            feature_dict[int(period[-1])].append('_'.join(period[:-2]))\n",
    "        else:\n",
    "            feature_dict[0].append(f)\n",
    "\n",
    "    feature_dict = dict(sorted(feature_dict.items()))\n",
    "    \n",
    "    for item in feature_dict.items():\n",
    "        if item[0] > 0:\n",
    "            features.extend([i + f'_prev_{item[0]}' for i in item[1]])\n",
    "        else:\n",
    "            features.extend([i for i in item[1]])\n",
    "\n",
    "    feature_dict['features'] = features + ['Pattern_Trend', 'STOCH_RSI', 'ttype']\n",
    "\n",
    "    return features, feature_dict\n",
    "\n",
    "def confident_score(y, oof, low_bound, high_bound):\n",
    "    ''' Consider only high confident objects for accuracy and precision scores calculation;\n",
    "        object probability must be lower than low_bound or higher than high_bound '''\n",
    "    pred_conf = np.zeros_like(oof)\n",
    "    pred_conf[oof > high_bound] = 1\n",
    "    pred_conf[oof < low_bound] = 0\n",
    "    # pred_conf_acc = pred_conf[(oof < low_bound) | (oof > high_bound)]\n",
    "    pred_conf_prec = pred_conf[(oof > high_bound)]\n",
    "    # y_conf_acc = y.values.reshape(-1,1)[(oof < low_bound) | (oof > high_bound)]\n",
    "    y_conf_prec = y.values.reshape(-1,1)[(oof > high_bound)]\n",
    "\n",
    "    return precision_score(y_conf_prec, pred_conf_prec), y_conf_prec.shape[0]/y.shape[0]\n",
    "\n",
    "train_test = 'full' # fold, test, full\n",
    "low_bound, high_bound = 0.31, 0.69\n",
    "feature_num = 160\n",
    "\n",
    "\n",
    "if CFG.ttype == 'buy':\n",
    "    params = {\n",
    "        'boosting_type': 'dart',\n",
    "        'n_estimators': 2800,\n",
    "        'learning_rate': 0.02,\n",
    "        #   'early_stopping_round': 50,\n",
    "        'max_depth': 10,\n",
    "        'colsample_bytree': 0.75,\n",
    "        'subsample': 0.85,\n",
    "        'subsample_freq': 1,\n",
    "        'num_leaves': 24,\n",
    "        'verbosity': -1,\n",
    "        'max_bin': 255,\n",
    "        'reg_alpha': 1e-6,\n",
    "        'reg_lambda': 1e-8,\n",
    "        'objective': 'binary',\n",
    "        # 'is_unbalance': True,\n",
    "        # 'class_weight': 'balanced',\n",
    "        'metric': 'average_precision'\n",
    "        }\n",
    "else:\n",
    "    params = {\n",
    "        'boosting_type': 'dart',\n",
    "        'n_estimators': 3300,\n",
    "        'learning_rate': 0.02,\n",
    "        #   'early_stopping_round': 50,\n",
    "        'max_depth': 10,\n",
    "        'colsample_bytree': 0.75,\n",
    "        'subsample': 0.85,\n",
    "        'subsample_freq': 1,\n",
    "        'num_leaves': 24,\n",
    "        'verbosity': -1,\n",
    "        'max_bin': 255,\n",
    "        'reg_alpha': 1e-6,\n",
    "        'reg_lambda': 1e-8,\n",
    "        'objective': 'binary',\n",
    "        # 'is_unbalance': True,\n",
    "        # 'class_weight': 'balanced',\n",
    "        'metric': 'average_precision'\n",
    "        }\n",
    "\n",
    "if CFG.train_LGBM:\n",
    "    fi = pd.read_csv(f'feature_importance_{CFG.ttype}.csv')\n",
    "    features, feature_dict = prepare_features(fi, feature_num)\n",
    "    oof, model = model_train(df, train_df, test_df, features, task_type=task_type, how='lgbm', n_folds=5, low_bound=low_bound, high_bound=high_bound, train_test=train_test)\n",
    "\n",
    "    if train_test == 'fold':\n",
    "        y = train_df['target']\n",
    "        oof_val_score = log_loss(y, oof)\n",
    "        oof_conf_prec_score, oof_conf_obj_pct = confident_score(y, oof, low_bound, high_bound)\n",
    "        print(f'Total fold Logloss: {oof_val_score}, Total confident objects precision: {oof_conf_prec_score}, Total % of confident objects: {oof_conf_obj_pct}')\n",
    "    elif train_test == 'test':\n",
    "        y_test = test_df['target']\n",
    "        test_val_score = log_loss(y_test, oof)\n",
    "        test_conf_prec_score, test_conf_obj_pct = confident_score(y_test, oof, low_bound, high_bound)\n",
    "        print(f'Total test Logloss: {test_val_score}, Total test confident objects precision: {test_conf_prec_score}, Total % of test confident objects: {test_conf_obj_pct}')\n",
    "    elif train_test == 'full':\n",
    "        joblib.dump(model, f'lgbm_{CFG.ttype}.pkl')\n",
    "        # save feature dictionary for further inference\n",
    "        with open(f'features_{CFG.ttype}.json', 'w') as f:\n",
    "            json.dump(feature_dict, f)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buy\n",
    "\n",
    "Total fold Logloss: 0.6702724113101635, Total confident objects precision: 0.7360515021459227, Total % of confident objects: 0.14209483152919652\n",
    "\n",
    "Total test Logloss: 0.6711832375966075, Total test confident objects precision: 0.7558139534883721, Total % of test confident objects: 0.12320916905444126\n",
    "\n",
    "Sell\n",
    "\n",
    "Total fold Logloss: 0.6426294842210379, Total confident objects precision: 0.7342618384401114, Total % of confident objects: 0.26703362094614697\n",
    "\n",
    "Total test Logloss: 0.6301778163097583, Total test confident objects precision: 0.8072916666666666, Total % of test confident objects: 0.26337448559670784"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count predictions according to pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3407\n",
       "0    3152\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_test == 'fold':\n",
    "    train_df.loc[:,'oof'] = oof >= high_bound\n",
    "    display(train_df.groupby('pattern')['oof'].agg(['mean', 'count']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
